# **Personal Research Portal (PRP) â€” AI Coding Assistant Impact Study**

Author: Jorge Urias  
Course: AI Model Development  
Phase: 2 â€” Ground the Research Domain  

---

# ğŸ“Œ Research Domain

Impact of AI coding assistants (e.g., GitHub Copilot, CodeWhisperer, ChatGPT) on:

- Developer productivity
- Code quality
- Skill formation
- Technical debt
- Long-term maintainability

---

# ğŸ¯ Main Research Question

> How do AI coding assistants affect productivity, code quality, and long-term software engineering outcomes?

---

# ğŸ§  Phase 2 Objective

Build a **research-grade Retrieval-Augmented Generation (RAG)** system with:

- Structured citations
- Traceable chunk-level evidence
- Logged retrieval + generation
- Reproducible evaluation pipeline
- Trust safeguards (no fabricated citations)

---

# ğŸš€ Quick Start (5-Minute Grader Path)

## 1ï¸âƒ£ Clone the Repository

```bash
git clone <repo_url>
cd Phase2
```

# 2ï¸âƒ£ Create Python Environment
```
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

All dependencies are pinned for reproducibility.

# 3ï¸âƒ£ Install Local LLM (Ollama Required)

This project uses a local LLM via Ollama for fully reproducible generation.

Install Ollama:
https://ollama.com

Pull the required model:

```
ollama pull llama3
```

Verify it works:

```
ollama run llama3
```

The system assumes Ollama is running at:

```
http://localhost:11434
```

# 4ï¸âƒ£ Run Full Evaluation Pipeline
```
python run_phase2.py
```

This single command will:

* Run all 20 evaluation queries
* Retrieve top-k evidence chunks
* Generate answers with structured citations
* Save full logs
* Score evaluation runs
* Print summary metrics

# ğŸ“Š Evaluation Design

Evaluation query set includes:

* 10 Direct questions
* 5 Synthesis (multi-hop) questions
* 5 Edge / ambiguity cases

Metrics:

* Groundedness (1â€“4)
* Citation correctness (1â€“4)
* Usefulness (1â€“4)

Evaluation logs stored in:

```
logs/eval_runs/
logs/evaluation_results/
```

# ğŸ§¾ Corpus

The system uses 15â€“30 research sources including:

* Peer-reviewed papers
* Technical reports
* Empirical studies

Each source includes required metadata:

* source_id
* title
* authors
* year
* source_type
* venue
* url_or_doi
* raw_path
* processed_path
* tags
* relevance_note

Metadata file:

```
data/data_manifest.csv
```

Raw artifacts stored under:

```
data/raw/
```

# ğŸ” RAG Architecture

**1.** Ingest PDFs â†’ parse and clean

**2.** Section-aware chunking

**3.** Embedding using sentence-transformers

**4.** FAISS vector index

**5.** Top-k retrieval

**6.** Local LLM generation (Ollama)

**7.** Structured citations: (source_id, chunk_id)

**8.** Logging of:

* Query
* Retrieved chunks
* Prompt version
* Model output

# ğŸ›¡ï¸ Trust Safeguards Implemented

* No fabricated citations allowed
* Strict abstention when insufficient evidence
* Structured citation enforcement
* Logged chunk IDs for traceability
* Evaluation explicitly flags invalid citation patterns

# ğŸ”§ Enhancement Implemented (Phase 2 Requirement)

Enhancement: Trust tightening + structured citation enforcement

Improvements from baseline:

* Reduced fabricated references
* Stronger abstention on missing evidence
* Citation format normalization
* Evaluation pipeline automation

ğŸ“ Repository Structure
```
Phase2/
  README.md
  requirements.txt
  AI_USAGE_LOG.md
  run_query.py
  run_phase2.py
  data/
    raw/
    processed/
    data_manifest.csv
  src/
    ingest/
    rag/
    eval/
  logs/
    eval_runs/
    evaluation_results/
  report/
    Phase2_Report.md
```

# ğŸ§ª Reproducibility Notes

* All Python dependencies pinned in `requirements.txt`
* Local LLM specified and documented
* All evaluation logs saved
* Raw research artifacts stored locally
* Single-command evaluation pipeline

# âš ï¸ Common Failure Modes Addressed

* Fabricated citations â†’ prevented
* Incorrect citation formatting â†’ flagged
* Overconfident answers â†’ guarded
* Missing evidence â†’ explicit abstention

# ğŸ“„ Deliverables Included

* Baseline RAG implementation
* Enhancement implementation
* Data manifest
* Evaluation logs (machine-readable)
* Evaluation report (3â€“5 pages)
* AI usage disclosure
* Reproducible one-command pipeline

# ğŸ“š AI Usage Disclosure

See:

```AI_USAGE_LOG.md```

# ğŸ Phase 2 Acceptance Test Checklist

* âœ” One command runs full evaluation
* âœ” Answers contain structured citations
* âœ” Citations resolve to real source text
* âœ” Logs saved
* âœ” At least one enhancement implemented
* âœ” Evaluation report includes failure cases

# ğŸ‘¨â€ğŸ’» Author

Jorge Urias

AI Model Development â€” Personal Research Portal Project

Carnegie Mellon University