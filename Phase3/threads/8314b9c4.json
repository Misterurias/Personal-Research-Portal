{
  "thread_id": "8314b9c4",
  "timestamp": "2026-03-02T02:32:44+00:00",
  "query": "How do AI-assisted coding tools impact developer productivity, code quality, and long-term technical debt across experience levels?",
  "answer": "How do AI-assisted coding tools impact developer productivity, code quality, and long-term technical debt across experience levels?\n\nInsufficient evidence in the current corpus.\n\nTo better answer this question, additional research is needed to examine how different project governance mechanisms moderate AI-induced technical debt, such as automated testing, modular architectures, or formalized review protocols. Future work may also explore heterogeneity across project types, identifying which OSS projects are most vulnerable to debt accumulation under AI-assisted development.\n\nReferences:\n(AIProdDecrease2024, AIProdDecrease2024_chunk_009)\n(EmpiricalToolAnalysis2025, EmpiricalToolAnalysis2025_chunk_002)\n(AIProdDecrease2024, AIProdDecrease2024_chunk_027)\n(AIProdDecrease2024, AIProdDecrease2024_chunk_028)\n(AIProdDecrease2024, AIProdDecrease2024_chunk_026)",
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.5607659220695496,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_009",
      "text": " Ramasubbu and Kemerer 2021). Both approaches have value: the former\nmetric-based techniques are scalable and actionable for tooling, while the later process indicators capture\nthe economic and human costs that managers and maintainers ultimately face.\nEmpirical studies across industry and OSS ecosystems consistently find that technical debt impairs long-\nrun productivity and increases maintenance burdens (Paramitha and Massacci 2023). Work in empirical\nsoftware engineering shows that higher measured debt correlates with increased bug rates, longer defect\nresolution times, and reduced velocity for feature delivery (Ramasubbu and Kemerer 2016). Rinta-Kahila\net al. (2023) further demonstrate that organizations can become \u201ctrapped\u201d in technical debt due to coor-\ndination failures, organizational inertia, and escalating switching costs. The introduction of GenAI tools\nsuch as GitHub Copilot represents a departure from these assumptions (Yeverechyahu et al. 2024). Unlike\nprior productivity-enhancing tools, GenAI dramatically lowers the marginal cost of producing code and\nreduces skill barriers to contribution (Peng et al. 2023). While prior studies document productivity gains\nfrom AI-assisted coding, they provide limited insight into how these gains translate into technical debt and\nmaintenance related challenges.\nFrom a technical debt perspective, GenAI may accelerate debt accumulation by increasing code volume\nwithout proportionate improvements in quality, the integration with the software, or architectural coher-\nence (Pimenova et al. 2025). By lowering the cost of producing code, AI-assisted programming encourages\nrapid iteration and experimentation, but can shift attention away from longer-term concerns such as main-\ntainability, readability, and alignment with existing system design (Barrett et al. 2023, Schreiber and Tippe\n2025). As a result, defects, inconsistencies, and design shortcuts may be introduced more quickly than\nthey can be identified and resolved. Over time, this imbalance can compound, transforming short-term pro-\nductivity gains into persistent maintenance obligations that must be absorbed by experienced developers\n(Eghbal 2020). While GenAI promises to enhance development speed and broaden participation, it may\nsimultaneously intensify the very technical debt that constrains system reliability, scalability, and long-run\nperformance (Ramasubbu and Kemerer 2021). If this logic is valid, we expect that GenAI may lead to a\ngreater accumulation of technical debt in OSS projects.\n8\nTable 1\nSelected Literature on Technical Debt and Software Maintenance\nStudy\nContext\nMethod\nMeasurement\nKey Findings\nBanker et al.\n(2021)\nCustomer\nrelationship\nmanagement\n(CRM)\nsystems in 26 firms\nEconometric analysis\nPercentage of customized codes in the\nCRM system that do not adhere to vendor-\nprescribed standard\nHigher technical debt is associated\nwith\nlower\nfirm\nperformance\nand\nreduced operational efficiency over\ntime.\nRamasubbu\n&\nKemerer\n(2021)\nOutsourced Commercial\nOff-The-Shelf\n(COT)\nenterprise systems\nEconometric analysis\nViolations of the design and programming\nstandards established by the vendor of the\nCOTS enterprise system\nActive remediation policies reduce\nlong-term\nmaintenance\ncosts,\nbut\nexcessive deferral leads to escalating\ntechnical debt.\nRamas"
    },
    {
      "rank": 2,
      "distance_l2": 0.5950642824172974,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_002",
      "text": " code \ngeneration tools, which are based on huge language models that have been trained with billions of lines \nof code, have been identified as the most powerful of the innovative technologies that will significantly \ncontribute to the developer's productivity, lessening of cognitive burden, and speeding up of software \ndelivery cycles [1, 2]. In this manner interaction with such tools as GitHub Copilot, Amazon \nCodeWhisperer, and ChatGPT-based coding assistants radically changes the way developers write and \nmaintain software since they all provide real-time code suggestions, automated bug fixes, and intelligent \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   \u25cf   Website: www.ijfmr.com       \u25cf   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n2\n \ncode completion capabilities [3].The acceptance of AI-assisted coding tools is getting faster, and it is \nrevealed by the latest industry surveys, which show that more than 65% of professional developers use AI \nsupport in some form as part of their daily routine [4]. These tools have been incorporated into the \ndevelopment processes of large tech companies that account for 30-50% productivity gains and have also \nreported significant time-to-market reductions for software products [5]. Nevertheless, the fast adoption \nof these tools has been so extensive that even empirical studies have not been able to catch up with their \nimplications on critical software engineering outcomes, like code quality, security, and long-term \nmaintainability, through rigorous research [6]. \nThe research gap is even more pronounced when the risk factors of AI-generated code are taken into \naccount. Initial experiments have pointed out issues such as security flaws, licensing confusion, and the \noccurrence of hidden bugs that will not be discovered during code reviewing process [7, 8]. Moreover, the \nimpact on the development of programmers' skills, particularly that of junior developers, who would \notherwise depend on AI-generated suggestions, is still unclear [9]. There being no empirical studies taking \na comprehensive approach to the assessment of these issues, the bottleneck of knowledge in software \nengineering research is in fact the multifaceted impacts of these issues. \nThis research paper fills this void by performing a large-scale controlled experiment whose main objective \nis to evaluate in a systematic way the impact of AI-assisted code generator tools on the three main \ndimensions: code quality, security vulnerability introduction, and developer productivity. Previous studies \nhave limited themselves to specific scenarios or synthetic benchmarks. On the contrary, our study will \ninvolve actual programming tasks in different languages and varying degrees of complexity, professional \ndevelopers of different skill and experience levels. Our assumption is that although the use of AI-assisted \ntools will increase productivity, at the same time, they might lead to the poor quality and insecure software \ndevelopment, which will need to be dealt with through proper industrial adoption strategies. \nResearch has contributed in three ways. To start with, the paper provided empirical evidence that through \nthe use of assistance from AI in code production, there was a significant impact on the software quality \nmetrics namely, cyclomatic complexity, maintainability index and code smell density. Next, the authors \nperformed a comprehensive examination of the security vulnerabilities related to AI-generated code in the \nvarious"
    },
    {
      "rank": 3,
      "distance_l2": 0.6057258248329163,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_027",
      "text": " the project. As a\nresult, maintainers are compelled to reallocate their time toward reviewing and managing code submissions\ninstead of writing new code.\n7.2.\nContributions and Future Research\nExtant research on AI pair programming has primarily emphasized productivity and efficiency gains, sug-\ngesting that tools such as GitHub Copilot can substantially accelerate software development (Peng et al.\n2023). While these benefits are evident in our data, our findings reveal a more nuanced set of consequences.\nIn particular, we show that AI-assisted programming also amplifies software maintenance challenges, espe-\ncially for core contributors who bear responsibility for code review and integration. Our individual-level\nanalysis demonstrates that while less-experienced contributors increase their output, experienced contrib-\nutors face higher review workloads and a concomitant decline in their own development activity. These\nresults highlight a redistribution of effort within OSS communities that has received limited attention in\nprior work.\nFrom a technical debt perspective, our findings suggest that AI-assisted programming alters the intertem-\nporal trade-off between short-term development speed and long-term maintainability. The shortcuts enabled\nby AI tools may accelerate the output while introducing code that is difficult to integrate, extend, or refactor.\nThe widespread use of AI-assisted pair programming - and, in extreme cases, \u201cvibe coding\u201d - can inject a\nlarger volume of difficult-to-maintain code (Pimenova et al. 2025, Fawzy et al. 2025) into software projects,\naccelerating the accumulation of technical debt. Such contributions create latent liabilities for projects, as\nmaintainers must later invest substantial effort to review, revise, or rewrite code to meet repository stan-\ndards. In this sense, AI does not merely increase the volume of contributions; it changes the composition of\nincoming code in ways that intensify technical debt accumulation.\nA key contribution of our study is to operationalize technical debt at its point of entry. We conceptual-\nize extensive PR rework as realized technical debt: the additional modification, coordination, and revision\n16 https://github.blog/news-insights/octoverse/octoverse-2024/\n24\neffort required to bring submitted code up to acceptable standards. This measure complements prior work\nthat captures technical debt through architectural metrics, defect accumulation, or long-run performance\noutcomes. By focusing on PR-level dynamics, we provide a micro-level view of how technical debt emerges\nin real time and how it is managed through ongoing maintenance effort.\nOur findings also raise concerns about the learning implications of AI-assisted development. With AI\nproviding rapid solutions, peripheral contributors may engage less deeply with underlying programming\nprinciples and best practices, resulting in code that is functional but brittle. This concern echoes evidence\nfrom other AI-augmented work settings, where less-experienced workers experience large productivity\ngains while more skilled workers see modest improvements and increased coordination burdens (Brynjolf-\nsson et al. 2025). In OSS settings, these dynamics can further worsen technical debt by weakening the\nfeedback loop between contribution and learning.\nThese insights point to several directions for future research. Scholars could examine how different\nproject governance mechanisms moderate AI-induced technical debt, such as automated testing, mod-\nular architectures, or formalized review protocols. Future work may also explore heterogeneity across\nproject types, identifying which OSS projects are most vulnerable to debt accumulation"
    },
    {
      "rank": 4,
      "distance_l2": 0.6487875580787659,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_028",
      "text": "les and best practices, resulting in code that is functional but brittle. This concern echoes evidence\nfrom other AI-augmented work settings, where less-experienced workers experience large productivity\ngains while more skilled workers see modest improvements and increased coordination burdens (Brynjolf-\nsson et al. 2025). In OSS settings, these dynamics can further worsen technical debt by weakening the\nfeedback loop between contribution and learning.\nThese insights point to several directions for future research. Scholars could examine how different\nproject governance mechanisms moderate AI-induced technical debt, such as automated testing, mod-\nular architectures, or formalized review protocols. Future work may also explore heterogeneity across\nproject types, identifying which OSS projects are most vulnerable to debt accumulation under AI-assisted\ndevelopment. More broadly, the dynamics documented here may extend beyond OSS to other knowledge-\nintensive domains where AI increases output without replacing expert judgment. As OSS components are\nincreasingly embedded in enterprise systems and public infrastructure (Nagle 2019), understanding how AI\nreshapes technical debt dynamics becomes critical not only for OSS sustainability but for the resilience of\nthe broader digital ecosystem.\nAs a concluding remark, the challenges observed in OSS, such as quality concerns and increased main-\ntenance burdens driven by productivity gains among newer and less-experienced contributors, should serve\nas an early warning for similar risks in other knowledge-intensive domains where AI is being promoted to\nboost productivity and innovation.\n25\nReferences\nAngrist JD, Pischke JS (2009) Mostly Harmless Econometrics: An Empiricist\u2019s Companion (Princeton University\nPress).\nBanker RD, Liang Y, Ramasubbu N (2021) Technical Debt and Firm Performance. Management Science 67(5):3174\u2013\n3194.\nBarrett C, Boyd B, Bursztein E, Carlini N, Chen B, Choi J, Chowdhury AR, Christodorescu M, Datta A, Feizi S, et al.\n(2023) Identifying and Mitigating the Security Risks of Generative AI. Foundations and Trends\u00ae in Privacy and\nSecurity 6(1):1\u201352.\nBrown N, Cai Y, Guo Y, Kazman R, Kim M, Kruchten P, Lim E, MacCormack A, Nord R, Ozkaya I, Sangwan R,\nSeaman C, Sullivan K, Zazworka N (2010) Managing Technical Debt in Software-reliant Systems. Proceedings\nof the FSE/SDP Workshop on Future of Software Engineering Research, 47\u201352, FoSER \u201910 (New York, NY,\nUSA: Association for Computing Machinery).\nBrynjolfsson E, Li D, Raymond LR (2025) Generative AI at Work. The Quarterly Journal of Economics 140(2):889\u2014\n-942.\nChen Z, Chan J (2024) Large Language Model in Creative Work: The Role of Collaboration Modality and User\nExpertise. Management Science 70(12):9101\u20139117.\nCrowston K, Wei K, Li Q, Howison J (2006) Core and Periphery in Free/libre and Open Source Software Team Com-\nmunications. Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS\u201906),\nvolume 6,"
    },
    {
      "rank": 5,
      "distance_l2": 0.649630069732666,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_026",
      "text": ". First, the introduction of GitHub Copilot leads to higher\ndevelopment activity at both the repository and individual levels, measured by commits and PR, consistent\nwith industry evidence on AI-driven productivity gains (Peng et al. 2023). Second, these gains are accompa-\nnied by a significant increase in maintenance-related activities, as AI-generated contributions require more\nrevisions before integration - an early indicator of technical debt accumulation. Third, the effects are highly\nheterogeneous: core contributors review more PRs, contribute fewer commits, and extend their mainte-\nnance responsibilities across a wider range of repositories, suggesting that AI-assisted contributions from\nperipheral developers increase coordination and review burdens.\nBy conceptualizing GenAI as an endogenous shock to software production, this study advances the tech-\nnical debt literature in several important ways. First, consistent with prior work linking technical debt to firm\nperformance (Banker et al. 2021) and remediation costs (Ramasubbu and Kemerer 2016, 2021), we demon-\nstrate that AI-assisted code increases realized remediation effort, measured through PR rework. Second, we\nshow that technical debt is increasingly an outdated workload distribution phenomenon: maintenance costs\nare concentrated among a shrinking pool of core contributors, whose own productive output declines as\nmaintenance demands rise. Third, our findings complement research on organizational design and auton-\nomy (Paramitha and Massacci 2023, Yoo et al. 2025) by revealing how technological change can exacerbate\nasymmetries in effort and responsibility, even when the OSS repository workflow remains unchanged.\n15 https://mashable.com/archive/heartbleed-bug-websites-affected\n23\nTo illustrate the scale of Copilot\u2019s impact on OSS communities, Microsoft core contributors in our dataset\nconduct on average, 976 commits, 160 PRs, and 166 PR reviews annually before its introduction. The\nincreased volume of code associated with Copilot adoption results in an additional workload \u2013 each core\ncontributor is expected to review approximately 10 more PRs annually. This added maintenance burden\ncorresponds to a reduction of 164 commits and 9 PR contributions per year per core contributor. More\ncritically, GitHub\u2019s 2024 surveys reveal that more than one-third of contributors to the 10 most popular OSS\nprojects made their first contribution after signing up for GitHub Copilot, highlighting a significant influx\nof new and often less experienced developers16.\nWith annual contributions to OSS projects approaching 1 billion, this surge in participation significantly\nincreases the burden on core contributors, who take on the maintenance related tasks in the project. As a\nresult, maintainers are compelled to reallocate their time toward reviewing and managing code submissions\ninstead of writing new code.\n7.2.\nContributions and Future Research\nExtant research on AI pair programming has primarily emphasized productivity and efficiency gains, sug-\ngesting that tools such as GitHub Copilot can substantially accelerate software development (Peng et al.\n2023). While these benefits are evident in our data, our findings reveal a more nuanced set of consequences.\nIn particular, we show that AI-assisted programming also amplifies software maintenance challenges, espe-\ncially for core contributors who bear responsibility for code review and integration. Our individual-level\nanalysis demonstrates that while less-experienced contributors increase their output, experienced"
    }
  ],
  "citations": [
    {
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_009"
    },
    {
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_002"
    },
    {
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_027"
    },
    {
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_028"
    },
    {
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_026"
    }
  ]
}