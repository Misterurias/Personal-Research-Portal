{
  "timestamp": "2026-03-02T04:08:53+00:00",
  "query": "What impact do AI coding assistants have on code quality?",
  "retrieval_query": "Impact of AI coding assistants on code quality over time.",
  "query_rewritten": true,
  "rewritten_query": "Impact of AI coding assistants on code quality over time.",
  "top_k": 6,
  "answer": "I can only provide answers based on the provided evidence chunks. Please specify which chunk you would like me to respond to.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.7086491584777832,
      "source_id": "EnterpriseImpact2024",
      "chunk_id": "EnterpriseImpact2024_chunk_023",
      "text": " vs. experience: Evaluating the usability of code generation tools\npowered by large language models. In Chi conference on human factors in computing systems extended abstracts. 1–7.\n[51] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray.\n2019. Human-AI collaboration in data science: Exploring data scientists’ perceptions of automated AI. Proceedings of the ACM on human-computer\ninteraction 3, CSCW (2019), 1–24.\nManuscript submitted to ACM\nExamining the Use and Impact of an AI Code Assistant on Dev. Productivity and Experience in the Enterprise\n13\n[52] Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agarwal, and Kartik Talamadupula.\n2021. Perfection not required? Human-AI partnerships in code translation. In Proceedings of the 26th International Conference on Intelligent User\nInterfaces. 402–412.\n[53] Justin D Weisz, Michael Muller, Steven I Ross, Fernando Martinez, Stephanie Houde, Mayank Agarwal, Kartik Talamadupula, and John T Richards.\n2022. Better together? an evaluation of ai-supported code translation. In Proceedings of the 27th International Conference on Intelligent User Interfaces.\n369–391.\n[54] Michel Wermelinger. 2023. Using github copilot to solve simple programming problems. In Proceedings of the 54th ACM Technical Symposium on\nComputer Science Education V. 1. 172–178.\n[55] Zhuohao Wu, Danwen Ji, Kaiwen Yu, Xianxu Zeng, Dingming Wu, and Mohammad Shidujaman. 2021. AI creativity and the human-AI co-creation\nmodel. In Human-Computer Interaction. Theory, Methods and Tools: Thematic Area, HCI 2021, Held as Part of the 23rd HCI International Conference,\nHCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part I 23. Springer, 171–190.\n[56] Frank F Xu, Bogdan Vasilescu, and Graham Neubig. 2022. In-ide code generation from natural language: Promise and challenges. ACM Transactions\non Software Engineering and Methodology (TOSEM) 31, 2 (2022), 1–47.\n[57] Zhen Yang, Fang Liu, Zhongxing Yu, Jacky Wai Keung, Jia Li, Shuo Liu, Yifan Hong, Xiaoxue Ma, Zhi Jin, and Ge Li. 2024. Exploring and unleashing\nthe power of large language models in automated code translation. Proceedings of the ACM on Software Engineering 1, FSE (2024), 1585–1608.\n[58] Burak Yetistiren, Isik Ozsoy, and Eray Tuzun. 2022. Assessing the quality of GitHub copilot’s code generation. In Proceedings of the 18th international\nconference on predictive models and data analytics in software engineering. 62–71.\n[59] Ramaz"
    },
    {
      "rank": 2,
      "distance_l2": 0.7245273590087891,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_002",
      "text": " code \ngeneration tools, which are based on huge language models that have been trained with billions of lines \nof code, have been identified as the most powerful of the innovative technologies that will significantly \ncontribute to the developer's productivity, lessening of cognitive burden, and speeding up of software \ndelivery cycles [1, 2]. In this manner interaction with such tools as GitHub Copilot, Amazon \nCodeWhisperer, and ChatGPT-based coding assistants radically changes the way developers write and \nmaintain software since they all provide real-time code suggestions, automated bug fixes, and intelligent \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n2\n \ncode completion capabilities [3].The acceptance of AI-assisted coding tools is getting faster, and it is \nrevealed by the latest industry surveys, which show that more than 65% of professional developers use AI \nsupport in some form as part of their daily routine [4]. These tools have been incorporated into the \ndevelopment processes of large tech companies that account for 30-50% productivity gains and have also \nreported significant time-to-market reductions for software products [5]. Nevertheless, the fast adoption \nof these tools has been so extensive that even empirical studies have not been able to catch up with their \nimplications on critical software engineering outcomes, like code quality, security, and long-term \nmaintainability, through rigorous research [6]. \nThe research gap is even more pronounced when the risk factors of AI-generated code are taken into \naccount. Initial experiments have pointed out issues such as security flaws, licensing confusion, and the \noccurrence of hidden bugs that will not be discovered during code reviewing process [7, 8]. Moreover, the \nimpact on the development of programmers' skills, particularly that of junior developers, who would \notherwise depend on AI-generated suggestions, is still unclear [9]. There being no empirical studies taking \na comprehensive approach to the assessment of these issues, the bottleneck of knowledge in software \nengineering research is in fact the multifaceted impacts of these issues. \nThis research paper fills this void by performing a large-scale controlled experiment whose main objective \nis to evaluate in a systematic way the impact of AI-assisted code generator tools on the three main \ndimensions: code quality, security vulnerability introduction, and developer productivity. Previous studies \nhave limited themselves to specific scenarios or synthetic benchmarks. On the contrary, our study will \ninvolve actual programming tasks in different languages and varying degrees of complexity, professional \ndevelopers of different skill and experience levels. Our assumption is that although the use of AI-assisted \ntools will increase productivity, at the same time, they might lead to the poor quality and insecure software \ndevelopment, which will need to be dealt with through proper industrial adoption strategies. \nResearch has contributed in three ways. To start with, the paper provided empirical evidence that through \nthe use of assistance from AI in code production, there was a significant impact on the software quality \nmetrics namely, cyclomatic complexity, maintainability index and code smell density. Next, the authors \nperformed a comprehensive examination of the security vulnerabilities related to AI-generated code in the \nvarious"
    },
    {
      "rank": 3,
      "distance_l2": 0.7423162460327148,
      "source_id": "EnterpriseImpact2024",
      "chunk_id": "EnterpriseImpact2024_chunk_001",
      "text": "Examining the Use and Impact of an AI Code Assistant on Developer\nProductivity and Experience in the Enterprise\nJUSTIN D. WEISZ, IBM Research, USA\nSHRADDHA KUMAR∗, Cisco Systems, Inc., India\nMICHAEL MULLER, IBM Research, USA\nKAREN-ELLEN BROWNE, IBM Software, Ireland\nARIELLE GOLDBERG, IBM Infrastructure, USA\nELLICE HEINTZE, IBM Software, Germany\nSHAGUN BAJPAI, IBM Software, India\nAI assistants are being created to help software engineers conduct a variety of coding-related tasks, such as writing, documenting, and\ntesting code. We describe the use of the watsonx Code Assistant (WCA), an LLM-powered coding assistant deployed internally within\nIBM. Through surveys of two user cohorts (N=669) and unmoderated usability testing (N=15), we examined developers’ experiences\nwith WCA and its impact on their productivity. We learned about their motivations for using (or not using) WCA, we examined their\nexpectations of its speed and quality, and we identified new considerations regarding ownership of and responsibility for generated\ncode. Our case study characterizes the impact of an LLM-powered assistant on developers’ perceptions of productivity and it shows\nthat although such tools do often provide net productivity increases, these benefits may not always be experienced by all users.\nCCS Concepts: • Human-centered computing →Empirical studies in HCI; Field studies; • Software and its engineering →\nCollaboration in software development; Automatic programming.\nAdditional Key Words and Phrases: Generative AI, LLM, software engineering, productivity, code assistant\nACM Reference Format:\nJustin D. Weisz, Shraddha Kumar, Michael Muller, Karen-Ellen Browne, Arielle Goldberg, Ellice Heintze, and Shagun Bajpai. 2025.\nExamining the Use and Impact of an AI Code Assistant on Developer Productivity and Experience in the Enterprise. In Extended\nAbstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA ’25), April 26-May 1, 2025, Yokohama, Japan. ACM,\nNew York, NY, USA, 21 pages. https://doi.org/10.1145/3706599.3706670\n1\nIntroduction\nAI assistants powered by large language models (LLMs) are becoming increasingly prevalent in the workplace. A\nnumber of commercial and open-source coding assistants have been released for software engineers, developers, and\n∗Work conducted while an employee of IBM Software, Kochi, India.\nAuthors’ Contact Information: Justin D. Weisz, jweisz@us.ibm.com, IBM Research, Yorktown Heights, NY, USA; Shraddha Kumar, shraddku@cisco.com,\nCisco Systems, Inc., Bangalore, India; Michael Muller, michael_muller@us.ibm.com, IBM Research, Cambridge, MA, USA; Karen-Ellen Browne, karen-\nellen@ibm.com, IBM Software, Dublin, Ireland; Arielle Goldberg, arielle.goldberg1@ibm.com, IBM Infrastructure, Poughkeepsie, NY, USA; Ellice Heintze,\nke.heintze@de.ibm.com, IBM Software, Boeblingen,"
    },
    {
      "rank": 4,
      "distance_l2": 0.750802755355835,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_003",
      "text": "olve actual programming tasks in different languages and varying degrees of complexity, professional \ndevelopers of different skill and experience levels. Our assumption is that although the use of AI-assisted \ntools will increase productivity, at the same time, they might lead to the poor quality and insecure software \ndevelopment, which will need to be dealt with through proper industrial adoption strategies. \nResearch has contributed in three ways. To start with, the paper provided empirical evidence that through \nthe use of assistance from AI in code production, there was a significant impact on the software quality \nmetrics namely, cyclomatic complexity, maintainability index and code smell density. Next, the authors \nperformed a comprehensive examination of the security vulnerabilities related to AI-generated code in the \nvarious programming languages and projects. Finally, the research gives the software organizations that \nwant to use AI tools good insights and practices for risk reduction. Thus, the implications of our results \nare very important for the education of software engineers, the industry's practices and the direction of \nfuture research in the area of AI and software development. \n \n2. Literature Review \nThe areas where artificial intelligence and software engineering meet have become the center of a huge \nnumber of research studies, with code generation and program synthesis being the two main areas. The \nfirst automated code generation attempts relied on template-based methods and rule-based systems \nproducing the so-called boilerplate codes from high-level specifications [10]. The deep learning era totally \nchanged the picture, with the application of sequence-to-sequence models and recurrent neural networks \nto the code synthesis tasks [11]. The introduction of the transformer architectures was the turning point, \nwith models such as CodeBERT and GraphCodeBERT being able to perform on a par with the best \nmethods in the problem categories of code understanding and generation [12, 13]. \nRecently, the development of large language models has further changed the scenery in code generation. \nFor instance, GPT-3 showed outstanding learning ability through a few examples for programming tasks \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n3\n \n[14], while Codex, the engine behind GitHub Copilot, scored highly in competitive programming \nproblems [15]. The following studies have looked into the models' capabilities in various programming \nlanguages and difficult algorithms [16, 17]. \nThe findings of empirical studies of AI-assisted coding tools presented a somewhat mixed picture. Ziegler \net al. indicated that developers using GitHub Copilot completed assignments on average 55.8% more \nquickly and reported higher satisfaction [18]. In contrast, Sandoval et al. indicated that code assemblages \nby AI showed significantly higher vulnerabilities, especially to the integrity of verification of input and \ncryptographic processes [19]. Perry et al. raised concerns about issues of misunderstanding in cloning \nobfuscated code in libraries; licensing problems in open-source projects; and the potential for unnoticed \nsubtle logical problems in open-source projects [20]. \nThe issue of how to assess and ensure the quality of AI-generated code remains an open question in \nresearch. Old-fashioned software measurement techniques have yielded different results depending on the \ntools and programming"
    },
    {
      "rank": 5,
      "distance_l2": 0.7525575757026672,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_001",
      "text": "International Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n1\n \nEmpirical Analysis of AI-Assisted Code \nGeneration Tools: Impact on Code Quality, \nSecurity and Developer Productivity \n \nMrs. Purvi Sankhe1, Dr. Neeta Patil2, Mrs. Minakshi Ghorpade 3,  \nMrs. Pratibha Prasad4, Mrs. Monisha Linkesh5 \n \n2Associate Professor, IT Department, Thakur College of Engineering and Technology, Mumbai India \n1,3,4,5Assistant Professor, IT Department, Thakur College of Engineering and Technology, Mumbai India \n \nAbstract \nAI-assisted code generation tools have been the main cause of the increase in practices like code \ncompletion, bug fixing, and documentation among developers. However, the main concern regarding their \neffects on code quality, security vulnerabilities, and developer productivity still lacks empirical evidence. \nObjective: This study conducts an empirical assessment of the AI-assisted code generation tools' \neffectiveness in terms of software quality metrics, security vulnerability introduction, and developer \nproductivity, depending on the programming languages and project complexities. Methodology: A \ncontrolled experiment was performed with 120 professional developers where they were divided into \nexperimental and control groups and 480 code modules were analyzed among Python, Java, JavaScript, \nand C++ projects. Cyclomatic complexity, maintainability index, and code smell density were the three \nparameters for measuring code quality. Static analysis tools were employed in the evaluation of security \nvulnerabilities, while productivity was gauged through measuring task completion time and conducting \ncognitive load surveys. Results: The use of AI-assistive tools lead to a 31.4% increase in average developer \nproductivity; however, 23.7% more security vulnerabilities were introduced in the codes generated. Code \nmaintainability went up 18.2%, while cyclomatic complexity decreased by 14.6%. The variations in \nprogramming languages were significant, with Python being the one that realized the highest quality \nimprovement (26.3%) and C++ the one that faced the most security risk increase (34.8%). \n \nKeywords: Large language models, Software security, Static code analysis, Cyclomatic complexity. \n \n1. Introduction \nThe software engineering landscape has been drastically changed by the integration of artificial \nintelligence and machine learning technologies into development environments. AI-assisted code \ngeneration tools, which are based on huge language models that have been trained with billions of lines \nof code, have been identified as the most powerful of the innovative technologies that will significantly \ncontribute to the developer's productivity, lessening of cognitive burden, and speeding up of software \ndelivery cycles [1, 2]. In this manner interaction with such tools as GitHub Copilot, Amazon \nCodeWhisperer, and ChatGPT-based coding assistants radically changes the way developers write and \nmaintain software since they all provide real-time code suggestions, automated bug fixes, and intelligent \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website:"
    },
    {
      "rank": 6,
      "distance_l2": 0.7549464106559753,
      "source_id": "OpenSourceImpact2024",
      "chunk_id": "OpenSourceImpact2024_chunk_029",
      "text": ". These normalized metrics allow us to \nassess quality relative to the volume of contributions. As reported in Table 9, we find that although Copilot \nadoption is associated with an increase in the total number of issues and bugs, the normalized measures \nremained statistically unchanged. These findings suggest that the increased issues and bug reports are due \nto a higher volume of code contributions, rather than a reduction in the quality of individual contributions.8 \n[insert Table 9 here] \n6.5 Core and Peripheral Developers \nOur H3a and H3b highlight some differential effects of AI pair programmers between peripheral and core \ndevelopers. To assess the effect of AI pair programmers on the relative project-level code contributions \nmade by peripheral developers compared to core developers (H3a), we compute the proportion of merged \nPRs from peripheral developers to the total number of merged PRs in each repository.9 A negative treatment \neffect estimate on this outcome variable indicates that after using Copilot, the proportion of code generated \nby peripheral developers among all code merged in a repository became lower, i.e. the adoption of AI pair \nprogrammers led to a relative decline in contribution share from peripheral developers.  \n \n8 We also examine whether Copilot’s effects differ by project complexity and find no significant differences between \nsimple and complex projects. Detailed discussions of the results are in Online Appendix J. \n9 Note that there are only two types of developers in a repository: core or peripheral developers. We use this measure \ninstead of the ratio of peripheral developers’ merged PRs to core developers’ merged PRs because the latter measure \ndoes not allow us to incorporate cases where core developers had zero merged PR in a repository in a month.  \n 31 \nTo assess the relative change in coordination time for integrating code contributed by peripheral \ndevelopers compared to the code from core developers (H3b), we calculate the ratio of the average time to \nmerge peripheral developers’ PRs to the overall average code-merging time in each repository. A positive \nestimate on this outcome would indicate that PRs from peripheral developers faced relatively longer \ncoordination time after Copilot adoption.  \nWe next examine the difference in productivity gain from AI pair programmers between peripheral \ndevelopers and core developers. Specifically, we compute the proportion of PRs from peripheral developers \nthat were merged within one, three, or ten days, and use each of these as the dependent variable. Negative \nestimates based on these outcome variables suggest that AI pair programmers led to less productivity gain \nfor peripheral developers than for core developers. \nAs shown in column (1) in Table 10, the proportion of merged PRs from peripheral developers \nsignificantly declined by 0.019 or 3.7%10. Additionally, as shown in column (2), peripheral developers \nexperienced an increase of 0.085 or 5.4%11 in their relative average merge time. Collectively, these findings \nsuggest that Copilot led to relatively fewer project-level code contributions from peripheral developers and \nlonger coordination time for them. The results, as well as the ones in columns (3) to (5) that use the \nproportion of timely merging of peripheral developers’ code as the dependent variables, suggest peripheral \ndevelopers realized less productivity gain from Copilot than core developers. \n[insert Table 10 here] \nTable 11 next reports the results on the mechanisms through which Copilot"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2.5-testing_system_rules_prompt3"
}