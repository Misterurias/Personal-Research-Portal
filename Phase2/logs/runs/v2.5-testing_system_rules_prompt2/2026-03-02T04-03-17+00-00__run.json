{
  "timestamp": "2026-03-02T04:03:17+00:00",
  "query": "How do AI coding tools affect junior versus senior developers?",
  "retrieval_query": "What are the differences in adoption and impact of AI coding tools between junior and senior developers?",
  "query_rewritten": true,
  "rewritten_query": "What are the differences in adoption and impact of AI coding tools between junior and senior developers?",
  "top_k": 6,
  "answer": "I can only answer based on the provided evidence chunks. Since you didn't provide any specific questions or topics to discuss, I will simply summarize the available information.\n\nThere are several research papers and studies discussed in these evidence chunks, including:\n\n1. A study on the impact of AI-assisted code generator tools on software development productivity, code quality, and security vulnerability introduction.\n2. Research on the role of generative AI in software development, particularly its influence on individual productivity on specific tasks.\n3. An investigation into the innovation capabilities of generative AI, comparing its influence on innovation in Python versus R.\n4. A study on the effects of AI tools on novice programming education, including their perceived benefits and drawbacks.\n\nThese studies aim to provide insights into the impact of AI-driven coding tools on software development, learning experiences, and essential programming skills.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.7449731826782227,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_010",
      "text": " went undetected in code reviews by participants compared to just 52% in human-written \ncode (p < 0.001). This suggests developers may be placing too much trust in AI-generated code, using less \nsecurity judgment in reviewing the AI-generated code compared to their own code, and devolving to a \nless strict and acute heuristic during their security review. \n4.4 Developer Experience and Learning Curve \nThe analysis of patterns of aid tool uptake revealed a learning curve. The experimental group reported \nincreasing productivity improvements across tasks: for Task 1, productivity improved by 18.2%; for Task \n2, it improved by 28.7%; for Task 3, it improved by 36.4%; and for Task 4, it improved by 41.8%, which \nsuggested that the developers were becoming better at using AI in helping them later in the tasks. This \nphenomenon was not as pronounced for the senior developers who showed consistent productivity, \nregardless of task. Experience had a significant impact on the relationship between AI tool use and code \nquality results (F (2,114) =7.43, p=0.001). The junior developers showed larger qualitative improvements \nyet produced a significantly larger proportion of bugs compared to the seniors. While junior developers \naccepted virtually all assistance provided by AI tools (89% of recommendations were accepted, p < .001), \nthe senior developers appeared to the center to weigh their engaging with the AI (62% acceptance of AI \nrecommendations) and could more easily articulate and locate fixes if bugs were identified by the AI tools. \nBoth think-aloud protocol and post-task interviews illuminated three different AI tool use strategies. The \nfirst strategy was the \"prompt-and-accept\" approach (38% of participants), in which participants took the \nAI-generated code suggestion fairly literally and made little modifications. The second strategy, \"iterative \nrefinement\", (47% of participants) used the AI suggestion as a starting point and modified and revised it \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n8\n \nsignificantly. The third strategy was \"validation-oriented\" (15% of participants) to seek reliability and use \nthe AI-generated output as a source of reference when writing code independently. The validation-focused \nstrategy produced mostly high-quality code, but with few productivity gains. \n \n5. Discussion \n5.1 Interpretation of Findings \nThe findings from this research reveal a complicated trade-off landscape in AI-assisted code generation, \nwhich challenges simplistic narrative accounts focused explicitly on productivity. The 31.4% productivity \nincrease is consistent with claims made by practitioners in the field, yet we observe that our results \nhighlight previously under-documented security concerns; further, this demonstrates an inherently basic \ntension associated with our fountain of AI-assisted software engineering: while speed may be enhanced, \nthere are potential security and maintainability trade-offs for future versions of AI-assisted software. The \nparticular performance of particular programming languages might also be providing data interpretations \nthat leave something to be desired: the improved results for Python programming likely derived from the \n"
    },
    {
      "rank": 2,
      "distance_l2": 0.7627207040786743,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_014",
      "text": " 23.7% and a total increase in critical severity of 89%. We also demonstrate \nthat some dimensions of code quality are improved with AI-assisted code generation tools (i.e., \nmaintainability, cyclomatic complexity) but caution is warranted with operational risks, to code itself (i.e. \nextra code duplication) and security vulnerabilities. We also examined differences across programming \nlanguages, and in particular, we found that while using AI-assisted code generation technologies is \nconstructive in Python, it warrants heightened caution around codex in C++ (to name only one). Finally, \nwhile we examined experience differences, we found that junior developers require support to prevent \nexcessive dependency on AI and senior developers could receive the maximum benefit from an AI tool \nwhen used independently. The security findings are quite concerning, which suggests that the injection of \nvulnerabilities is potentially higher and the chances of being detected is lowered, thus introducing grave \nrisks for organizations. \nSoftware organizations need to introduce processes for security review, advanced training, and the use of \nautomated security analysis in order to recognize possible patterns related to AI-generated code. It is no \nlonger possible to assume AI-generated code is unsafe or that the software development processes you \nhave in place will contain the risks associated with using AI-generated code based on the evidence we \npresent. AI-generated code is a fundamentally transformative and irreversibly changing practice in the \nsoftware engineering of the discipline and the question is how we can achieve the benefit and reduce risk \nthrough additional empirical research and the introduction of specific practices for AI security while \ncontinuing to have experts who are humans. Our research offers organizations an evidence-based basis for \nthe implementation of the AI tool and provides a benchmark for future longitudinal research design of \nlong-term outcomes of the analysis of the argued effort of transformational technology for deployment. \n \n7. References \n1. Chen, M., Tworek, J., Jun, H., et al. (2024). Evaluating large language models trained on code. ACM \nTransactions on Software Engineering and Methodology, 33(4), 1-42. \n2. Barke, S., James, M. B., & Polikarpova, N. (2023). Grounded Copilot: How programmers interact \nwith code-generating models. Proceedings of the ACM on Programming Languages, 7(OOPSLA1), \n85-111. \n3. Vaithilingam, P., Zhang, T., & Glassman, E. L. (2024). Expectation vs. experience: Evaluating the \nusability of code generation tools powered by large language models. CHI Conference on Human \nFactors in Computing Systems, 1-23. \n4. Kalliamvakou, E., Bird, C., Zimmermann, T., et al. (2024). The impact of AI on developer \nproductivity: Evidence from GitHub Copilot. IEEE Software, 41(3), 34-42. \n5. Peng, S., Kalliamvakou, E., Cihon, P., & Demirer, M. (2023). The impact of AI on developer \nproductivity: Findings from a study of GitHub Copilot. arXiv preprint arXiv:2302.06590. \nInternational Journal for Multidisciplinary Research (IJFMR) \n \n"
    },
    {
      "rank": 3,
      "distance_l2": 0.8292016983032227,
      "source_id": "OpenSourceImpact2024",
      "chunk_id": "OpenSourceImpact2024_chunk_029",
      "text": ". These normalized metrics allow us to \nassess quality relative to the volume of contributions. As reported in Table 9, we find that although Copilot \nadoption is associated with an increase in the total number of issues and bugs, the normalized measures \nremained statistically unchanged. These findings suggest that the increased issues and bug reports are due \nto a higher volume of code contributions, rather than a reduction in the quality of individual contributions.8 \n[insert Table 9 here] \n6.5 Core and Peripheral Developers \nOur H3a and H3b highlight some differential effects of AI pair programmers between peripheral and core \ndevelopers. To assess the effect of AI pair programmers on the relative project-level code contributions \nmade by peripheral developers compared to core developers (H3a), we compute the proportion of merged \nPRs from peripheral developers to the total number of merged PRs in each repository.9 A negative treatment \neffect estimate on this outcome variable indicates that after using Copilot, the proportion of code generated \nby peripheral developers among all code merged in a repository became lower, i.e. the adoption of AI pair \nprogrammers led to a relative decline in contribution share from peripheral developers.  \n \n8 We also examine whether Copilot’s effects differ by project complexity and find no significant differences between \nsimple and complex projects. Detailed discussions of the results are in Online Appendix J. \n9 Note that there are only two types of developers in a repository: core or peripheral developers. We use this measure \ninstead of the ratio of peripheral developers’ merged PRs to core developers’ merged PRs because the latter measure \ndoes not allow us to incorporate cases where core developers had zero merged PR in a repository in a month.  \n 31 \nTo assess the relative change in coordination time for integrating code contributed by peripheral \ndevelopers compared to the code from core developers (H3b), we calculate the ratio of the average time to \nmerge peripheral developers’ PRs to the overall average code-merging time in each repository. A positive \nestimate on this outcome would indicate that PRs from peripheral developers faced relatively longer \ncoordination time after Copilot adoption.  \nWe next examine the difference in productivity gain from AI pair programmers between peripheral \ndevelopers and core developers. Specifically, we compute the proportion of PRs from peripheral developers \nthat were merged within one, three, or ten days, and use each of these as the dependent variable. Negative \nestimates based on these outcome variables suggest that AI pair programmers led to less productivity gain \nfor peripheral developers than for core developers. \nAs shown in column (1) in Table 10, the proportion of merged PRs from peripheral developers \nsignificantly declined by 0.019 or 3.7%10. Additionally, as shown in column (2), peripheral developers \nexperienced an increase of 0.085 or 5.4%11 in their relative average merge time. Collectively, these findings \nsuggest that Copilot led to relatively fewer project-level code contributions from peripheral developers and \nlonger coordination time for them. The results, as well as the ones in columns (3) to (5) that use the \nproportion of timely merging of peripheral developers’ code as the dependent variables, suggest peripheral \ndevelopers realized less productivity gain from Copilot than core developers. \n[insert Table 10 here] \nTable 11 next reports the results on the mechanisms through which Copilot"
    },
    {
      "rank": 4,
      "distance_l2": 0.836352527141571,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_002",
      "text": " code \ngeneration tools, which are based on huge language models that have been trained with billions of lines \nof code, have been identified as the most powerful of the innovative technologies that will significantly \ncontribute to the developer's productivity, lessening of cognitive burden, and speeding up of software \ndelivery cycles [1, 2]. In this manner interaction with such tools as GitHub Copilot, Amazon \nCodeWhisperer, and ChatGPT-based coding assistants radically changes the way developers write and \nmaintain software since they all provide real-time code suggestions, automated bug fixes, and intelligent \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n2\n \ncode completion capabilities [3].The acceptance of AI-assisted coding tools is getting faster, and it is \nrevealed by the latest industry surveys, which show that more than 65% of professional developers use AI \nsupport in some form as part of their daily routine [4]. These tools have been incorporated into the \ndevelopment processes of large tech companies that account for 30-50% productivity gains and have also \nreported significant time-to-market reductions for software products [5]. Nevertheless, the fast adoption \nof these tools has been so extensive that even empirical studies have not been able to catch up with their \nimplications on critical software engineering outcomes, like code quality, security, and long-term \nmaintainability, through rigorous research [6]. \nThe research gap is even more pronounced when the risk factors of AI-generated code are taken into \naccount. Initial experiments have pointed out issues such as security flaws, licensing confusion, and the \noccurrence of hidden bugs that will not be discovered during code reviewing process [7, 8]. Moreover, the \nimpact on the development of programmers' skills, particularly that of junior developers, who would \notherwise depend on AI-generated suggestions, is still unclear [9]. There being no empirical studies taking \na comprehensive approach to the assessment of these issues, the bottleneck of knowledge in software \nengineering research is in fact the multifaceted impacts of these issues. \nThis research paper fills this void by performing a large-scale controlled experiment whose main objective \nis to evaluate in a systematic way the impact of AI-assisted code generator tools on the three main \ndimensions: code quality, security vulnerability introduction, and developer productivity. Previous studies \nhave limited themselves to specific scenarios or synthetic benchmarks. On the contrary, our study will \ninvolve actual programming tasks in different languages and varying degrees of complexity, professional \ndevelopers of different skill and experience levels. Our assumption is that although the use of AI-assisted \ntools will increase productivity, at the same time, they might lead to the poor quality and insecure software \ndevelopment, which will need to be dealt with through proper industrial adoption strategies. \nResearch has contributed in three ways. To start with, the paper provided empirical evidence that through \nthe use of assistance from AI in code production, there was a significant impact on the software quality \nmetrics namely, cyclomatic complexity, maintainability index and code smell density. Next, the authors \nperformed a comprehensive examination of the security vulnerabilities related to AI-generated code in the \nvarious"
    },
    {
      "rank": 5,
      "distance_l2": 0.8451576828956604,
      "source_id": "OpenSourceImpact2024",
      "chunk_id": "OpenSourceImpact2024_chunk_006",
      "text": " of generative AI tools—because these AI tools encourage \ndevelopers’ participation in non-coding activities such as discussions, they could lead to longer \ncoordination time in order to reconcile different ideas and perspectives among developers. \nThird, our study adds to the literature that explores the heterogeneity in the roles of generative AI \namong individuals (Dell'Acqua et al. 2023, Demirci et al. 2025). Prior studies have focused on how \nindividual skills play a role in shaping the effect of generative AI tools on completing discrete tasks and \nthey found that individuals with lower skills usually obtain greater productivity gain from these tools than \nhighly skilled individuals (e.g., Peng et al. 2023, Cui et al. 2024). Our results draw a sharp contrast with \nthese findings, as we demonstrate that peripheral developers obtain less productivity gain from AI pair \nprogrammers than core developers in OSS settings, potentially because the former do not possess important \nand necessary contextual knowledge about an OSS project to effectively use the AI tools. \n2. Literature Review  \n2.1 Generative AI in Software Development \nA growing body of literature has started to examine the impact of generative AI on software development. \nMost studies have focused on the implications of generative AI for individual productivity on specific tasks. \n 6 \nFor example, Imai (2022) finds that GitHub Copilot produces more lines of code than a human pair \nprogrammer when completing a task in Python. Peng et al. (2023) find that GitHub Copilot enables \nindividual developers to implement an HTTP server 55.8% faster than those not using the tool. Hoffmann \net al. (2024) show that GitHub Copilot causes individual developers to shift focus towards coding tasks and \naway from project management.  \nDespite these insights, research on how generative AI influences project-level outcomes for \ncomplex tasks involving multiple developers remains limited. Yeverechyahu et al. (2024) investigate the \ninnovation capabilities of generative AI, particularly its role in extrapolative versus interpolative thinking, \nand compare its influence on innovation in Python versus R. Different from the existing literature and built \nupon the OSS literature, our hypotheses are motivated by the unique characteristics of OSS, namely, the \nsoftware development process in an open and collaborative environment. Because participation is often \nvoluntary and coordination does not follow formal centralized processes in this environment, it remains \nunclear how generative AI influences open participation in both coding and non-coding activities, as well \nas team coordination, all of which could have important implications for project-level software \ndevelopment productivity. \nIn addition, existing research that explored heterogeneity in the roles of generative AI among \nindividuals has mostly focused on understanding the differential effects between workers with high skills \nagainst those with low skills for discrete tasks (e.g., Cui et al. 2024, Brynjolfsson et al. 2025). However, it \nremains unclear whether the results hold in settings with complex tasks that require not only skills but also \ncontextual knowledge and team collaboration. In the context of OSS development, the distinction between \ncore and peripheral developers lies not in their programming skills, but in their roles, responsibilities, and \nthe resulting level of contextual knowledge about a focal project (Crowston et al. 2006, Setia et al."
    },
    {
      "rank": 6,
      "distance_l2": 0.8485612869262695,
      "source_id": "NoviceProgramming2024",
      "chunk_id": "NoviceProgramming2024_chunk_001",
      "text": "Citation: Zviel-Girshin, R. The Good\nand Bad of AI Tools in Novice\nProgramming Education. Educ. Sci.\n2024, 14, 1089. https://doi.org/\n10.3390/educsci14101089\nAcademic Editors: Julie Delello and\nRochell McWhorter\nReceived: 26 August 2024\nRevised: 29 September 2024\nAccepted: 30 September 2024\nPublished: 6 October 2024\nCopyright:\n© 2024 by the author.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\neducation \nsciences\nArticle\nThe Good and Bad of AI Tools in Novice Programming Education\nRina Zviel-Girshin\nThe Center for Research in Technological and Engineering Education, Faculty of Engineering,\nRuppin Academic Center, Kfar Monash 4025000, Israel; rinazg@ruppin.ac.il\nAbstract: As AI coding tools become more prevalent in programming, it is essential to understand\nhow they influence programming education. This study, conducted in a first-semester Introduction\nto Programming course, aimed to determine the positive and negative effects of these tools on\nstudents’ learning experiences and their ability to develop essential programming skills. Using a\nmixed-methods approach, we collected data from 73 teams of engineering students over a 12-week\nperiod. Students completed surveys and reported on their AI tool usage. We analyzed this data\nquantitatively to identify trends in tool familiarity, usage, and student satisfaction. Additionally,\nqualitative analysis of student reports provided insights into the specific ways AI tools were used\nand their perceived benefits and drawbacks. The findings revealed a significant increase in AI tool\nfamiliarity (from 28% to 100%) and usage among students. Students’ satisfaction with AI tools\nimproved over time. The most prevalent tasks for which novice programmers used AI tools included\ncreating comments (91.7%), identifying and correcting bugs (80.2%), and seeking information (68.5%),\nwhile other tasks were less common. While these tools offered benefits like assisting in learning and\nenhancing real-world relevance, they also raised concerns about cheating, over-reliance on AI tools,\nand a limited understanding of core programming concepts.\nKeywords: artificial intelligence (AI); AI in education; programing education; introduction to\nprogramming; AI coding tools\n1. Introduction\nThe integration of Artificial Intelligence (AI) and AI-driven coding tools in program-\nming education has opened new avenues for enhancing both the teaching and learning\nexperience. These tools, while offering significant benefits, can also be a double-edged\nsword. Our study raises important questions about the AI tools’ long-term impact on\nstudents’ understanding and proficiency. The potential of AI tools to transform education\nis undeniable. They can automate routine coding tasks, provide instant feedback, improve\ndebugging and troubleshooting, and offer personalized, student-centered learning experi-\nences. However, their use also introduces challenges, particularly regarding the balance\nbetween automation and preserving essential programming skills [1–5].\nAI in education is rapidly emerging as a key area of focus in educational technology,"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2.5-testing_system_rules_prompt2"
}