{
  "timestamp": "2026-03-02T03:44:08+00:00",
  "query": "Are experienced developers more effective when using AI assistants?",
  "retrieval_query": "Effective use of AI assistants by experienced developers.",
  "query_rewritten": true,
  "rewritten_query": "Effective use of AI assistants by experienced developers.",
  "top_k": 6,
  "answer": "I can only answer based on the provided evidence chunks.\n\nPlease provide the specific question or topic you'd like me to address, and I'll do my best to respond using only the information from the provided evidence chunks.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.7207889556884766,
      "source_id": "SkillFormation2026",
      "chunk_id": "SkillFormation2026_chunk_006",
      "text": " code, fix\nerrors, and explain algorithmic concepts; students with less coding proficiency were more likely to seek AI\nassistance. Other works use surveys to find that students may be hesitant to use AI coding assistant tools\ndue to “dependence worry” (i.e., overreliance on coding tools) [Pan et al., 2024]. For formal methods, Prasad\net al. coded the different ways in which students used LLMs for course work and found that upper-year\nstudents taking the class did not rely on LLM assistance and only asked a few questions at the beginning.\nUser studies have also been conducted in the professional development environments. Wang et al. study\ndifferent patterns in usage between users with and without chat access to AI models in completing coding\npuzzles and development tasks. They found rich interaction patterns including interactive debugging, code\ndiscussions, and asking specific questions. Participants ranged from asking ChatGPT to do then the entire\nproblem (lowest quality code output) to only asking minimal questions (highest efficiency). Other studies\nhave reported that AI tools help the software development process through easier access to documentation\nand accurate generation code for specific APIs [Pinto et al., 2024].\n3\nFramework\nProfessional Skill Acquisition\nThe “learning by doing” philosophy has been suggested by many learning\nframeworks such as the Kolb’s experiential learning cycle, and the Problem-Based Learning (PBL) [Kolb,\n2014, Schmidt, 1994]. The frameworks connect the completion of real-world tasks with the learning of\nnew concepts and the development of new skills. Experiential learning has also been explored specifically\nin software engineering courses in higher education in order to mimic solving problems in a professional\nsetting [Gonzalez-Huerta et al., 2020]. In its simplest form, we model AI tool assistance as taking a different\nlearning path than without AI. We hypothesize that using AI tools to generate code in the development\nprocess effectively amounts to taking a shortcut to task completion without a pronounced learning stage.\nAI for Coding Usage Patterns\nPrior works have found that humans use AI in many different ways\nfor coding: from question answering to writing code, to debugging [Poitras et al., 2024, Wang et al., 2020,\nPinto et al., 2024]. In our framework, different ways of using AI assistance represent different learning paths\ntaken to reach the goals of completing the task. We analyze these different usage patterns in the qualitative\nanalysis of this work (Section 6).\nResearch Questions\nBased on this background, we focus on on-the-job learning: settings where workers\nmust acquire new skills to complete tasks. We seek to understand both the impact of AI on productivity\nand skill formation. We ask whether AI assistance presents a tradeoff between immediate productivity and\nlonger-term skill development or if AI assistance presents a shortcut to enhance both. Our research questions\nare as follows:\n• RQ1: Does AI assistance improve task completion productivity when new skills are required?\n4\nWith AI Assistance\nNovice \nWorker\nLearning\nTask \nCompletion\nWithout AI Assistance\nFigure 2: With AI assistance becoming more ubiquitous in the workplace, novice workers may complete tasks\nwithout the same learning outcomes. Our experiments aim to investigate the process of task completion\nrequiring a new skill to understand the impact of AI assistance on"
    },
    {
      "rank": 2,
      "distance_l2": 0.7290253639221191,
      "source_id": "SkillFormation2026",
      "chunk_id": "SkillFormation2026_chunk_002",
      "text": " workers. As humans rely on AI for skills such as brainstorming,\nwriting, and general critical thinking, the development of these skills may be significantly altered depending\non how AI assistance is used.\nSoftware engineering, in particular, has been identified as a profession in which AI tools can be readily applied\nand AI assistance significantly improves productivity in daily tasks [Peng et al., 2023, Cui et al., 2024].\nJunior or novice workers, in particicular, benefit most from AI assistance when writing code. In high-stakes\napplications, AI written code may be debugged and tested by humans before a piece of software is ready\nfor deployment. This additional verification that enhances safety is only possible when human engineers\nthemselves have the skills to understand code and identify errors. As AI development progresses, the problem\nof supervising more and more capable AI systems becomes more difficult if humans have weaker abilities\n∗Work done as a part of the Anthropic Fellows Program, judy@anthropic.com\n†Anthropic, atamkin@anthropic.com\n1\narXiv:2601.20245v2  [cs.CY]  1 Feb 2026\nAI \nDelegation\nConceptual \nInquiry\nIterative AI \nDebugging\nHybrid \nCode-\nExplanation\nProgressive \nAI Reliance\nQuiz Score\nCompletion Time\n24min\n68%\nGeneration-\nThen-\nComprehension\n24min\n86%\n22min\n65%\n31min\n24%\n22min\n35%\n19.5min\n39%\nThe Impact of AI Assistance on Coding Speed and Knowledge Quiz\nAI Usage Patterns \nFigure 1: Overview of results: (Left) We find a significant decrease in library-specific skills (conceptual\nunderstanding, code reading, and debugging) among workers using AI assistance for completing tasks with a\nnew python library. (Right) We categorize AI usage patterns and found three high skill development patterns\nwhere participants stay cognitively engaged when using AI assistance.\nto understand code [Bowman et al., 2022]. When complex software tasks require human-AI collaboration,\nhumans still need to understand the basic concepts of code development even if their software skills are\ncomplementary to the strengths of AI [Wang et al., 2020]. The combination of persistent competency\nrequirements in high-stakes settings and demonstrated productivity gains from AI assistance makes software\nengineering an ideal testbed for studying how AI affects skill formation.\nWe investigate whether using and relying on AI affects the development of software engineering skills [Handa\net al., 2025]. Based on the rapid adoption of AI for software engineering, we are motivated by the scenario of\nengineers acquiring new skills on the job. Although the use of AI tools may improve productivity for these\nengineers, would they also inhibit skill formation? More specifically, does an AI-assisted task completion\nworkflow prevent engineers from gaining in-depth knowledge about the tools used to complete these tasks?\nWe run randomized experiments that measure skill formation by asking participants to complete coding\ntasks with a new library that they have not used before. This represents one way in which engineers acquire\nand learn new skills, since new libraries are frequently introduced in languages such as Python. We then\nevaluate their competency with the new library. Our main research questions are (1) whether AI improves\nproductivity for a coding task requiring"
    },
    {
      "rank": 3,
      "distance_l2": 0.7589421272277832,
      "source_id": "CopilotExperiment2023",
      "chunk_id": "CopilotExperiment2023_chunk_001",
      "text": "The Impact of AI on Developer Productivity:\nEvidence from GitHub Copilot\nSida Peng,1∗Eirini Kalliamvakou,2 Peter Cihon,2 Mert Demirer3\n1Microsoft Research, 14820 NE 36th St, Redmond, USA\n2GitHub Inc., 88 Colin P Kelly Jr St, San Francisco, USA\n3MIT Sloan School of Management, 100 Main Street Cambridge, USA\n∗To whom correspondence should be addressed; E-mail: sidpeng@microsoft.com.\nAbstract\nGenerative AI tools hold promise to increase human productivity. This paper presents re-\nsults from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited\nsoftware developers were asked to implement an HTTP server in JavaScript as quickly as\npossible. The treatment group, with access to the AI pair programmer, completed the task\n55.8% faster than the control group. Observed heterogenous effects show promise for AI\npair programmers to help people transition into software development careers.\nIntroduction\nArtiﬁcial intelligence (AI) applications hold promise to increase human productivity. A va-\nriety of AI models have demonstrated human-level capabilities in ﬁelds ranging from natural\nlanguage understanding to image recognition [Zhang et al., 2022]. As these systems are de-\nployed in the real-world, how do they change labor productivity? While there is a growing\nliterature studying perceptions of AI tools, how people use them, and their implications for\nsecurity and education [Nguyen and Nadi, 2022, Barke et al., 2022, Finnie-Ansley et al., 2022,\nSandoval et al., 2022] there has been little research on productivity impacts of AI-powered tools\n1\narXiv:2302.06590v1  [cs.SE]  13 Feb 2023\nin professional contexts, cf. [Mozannar et al., 2022, Vaithilingam et al., 2022, Ziegler et al., 2022].\nThe potential productivity impacts of AI have major implications for the labor market and\nﬁrms, including changes in employment, skills, and ﬁrm organization [Raj and Seamans, 2018,\nAgrawal et al., 2019].\nThis paper studies the productivity effects of AI tools on software development. We present\na controlled trial of GitHub Copilot, an AI pair programmer that suggests code and entire func-\ntions in real time based on context. GitHub Copilot is powered by OpenAI’s generative AI\nmodel, Codex [Chen et al., 2021]. In the trial, programmers were tasked and incentivized to\nimplement an HTTP server in JavaScript as quickly as possible. The treated group had access\nto GitHub Copilot and watched a brief video explaining how to use the tool. The control group\ndid not have access to GitHub Copilot but was otherwise unconstrained, i.e., they were free to\nuse internet search and Stack Overﬂow to complete the task.\nThe performance difference between treated and control groups are statistically and practi-\ncally signiﬁcant: the treated group completed the task 55.8% faster (95% conﬁdence interval:\n21-89%). Developers with less programming"
    },
    {
      "rank": 4,
      "distance_l2": 0.7648480534553528,
      "source_id": "EnterpriseImpact2024",
      "chunk_id": "EnterpriseImpact2024_chunk_010",
      "text": " tool is so new and very few people on my team use it. There is an inherent suspicion against\nAI-generated code.” Although only two respondents raised this issue, it may be important for organizational leaders to\nfoster a culture in which AI assistance is viewed as acceptable to garner wide-spread adoption.\nFinally, we discovered a small group of technical writers who found utility in using WCA to understand technical\nconcepts without having to disturb their developer counterparts. R1.57 remarked, “My favorite feature is to understand\nthe technical terms and code provided by the Dev. This reduces the time in understanding the API terms and code rather\nManuscript submitted to ACM\nExamining the Use and Impact of an AI Code Assistant on Dev. Productivity and Experience in the Enterprise\n7\nthan discussing with the Dev.” Multiple respondents desired using WCA to “create customer facing documentation”\n(R1.27) and “help me writ[e] drafts following IBM content guidelines.” (R1.68). These “off-label” use cases by people in\ndeveloper-adjacent roles surprised us and indicate the importance of taking a holistic view on the potential beneficiaries\nof AI code assistants.\n4.2\nUse of generated content\nRespondents reported using generated outputs – code, documentation, unit tests, and explanations – in different ways.\nOverall, the use of generated outputs without modification was not common (2-4% of respondents reported doing\nthis, depending on output type); rather, respondents often modified outputs before using them (9-19%) or used them\nfor another purpose, such as learning something new (23-35%) or getting new ideas (24-37%). Users described how\n“the results give me new ideas” (R2.180) and “It is very helpful to get started writing code in a new language” (R2.626)\nby “recommend[ing] an approach I haven’t thought of or I wasn’t even aware of” (R2.405). P1 described how “creating\ndiagrams in markdown works from the code.” Users also talked about how WCA helped them recall “concepts which may\nbe I have forgotten during [the] course of time” (R2.296) and aiding them when “[I] know what to do, but don’t know how\nto do it or forgot about that.” (R2.292). These uses reinforce the value that generative AI provides in helping people\nlearn [1, 6, 49, 59].\n4.3\nImpact on productivity\nWe evaluated the impact of WCA on respondents’ perceptions of productivity using multiple measures: 7-point semantic\ndifferential scales14 that assessed effort, quality, and speed [53] and a 4-item scale of self-efficacy15 (derived from [44]).\nOverall, respondents felt that WCA made their work easier (M (SD) = .78 (1.45), t(609) = 13.35, p < .001, 95% CI =\n[.67, .90]), of a better quality (M (SD) = .66 (1.25), t(603) = 13.02, p < .001, 95% CI = [.56, .76]), and faster (M (SD) = .57\n(1.48), t(606) = 9.57, p"
    },
    {
      "rank": 5,
      "distance_l2": 0.7680898904800415,
      "source_id": "EnterpriseImpact2024",
      "chunk_id": "EnterpriseImpact2024_chunk_017",
      "text": "2024).\nWith the rapid pace of advancement in AI, we anticipate some issues experienced by our users, especially regarding\nquality and speed, will naturally diminish as model performance increases. What won’t change is the need for human\ningenuity and insight to determine what software systems to build, even if the mechanics of how those systems are\nbuilt are increasingly aided by AI.\nManuscript submitted to ACM\nExamining the Use and Impact of an AI Code Assistant on Dev. Productivity and Experience in the Enterprise\n11\nAcknowledgments\nWe thank Katharina Schippert and Robin Auer for their support in defining the WCA user research program and\nrecruiting participants for our studies. We also thank Keri Olson and Melissa Modjeski whose support made this research\npossible. Finally, we thank all of our users who provided us with valuable feedback.\nReferences\n[1] Ibrahim Adeshola and Adeola Praise Adepoju. 2023. The opportunities and challenges of ChatGPT in education. Interactive Learning Environments\n(2023), 1–14.\n[2] Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Unified pre-training for program understanding and generation.\narXiv preprint arXiv:2103.06333 (2021).\n[3] Zahra Ashktorab, Michael Desmond, Josh Andres, Michael Muller, Narendra Nath Joshi, Michelle Brachman, Aabhas Sharma, Kristina Brimijoin,\nQian Pan, Christine T Wolf, et al. 2021. Ai-assisted human labeling: Batching for efficiency without overreliance. Proceedings of the ACM on\nHuman-Computer Interaction 5, CSCW1 (2021), 1–27.\n[4] Zahra Ashktorab, Qian Pan, Werner Geyer, Michael Desmond, Marina Danilevsky, James M Johnson, Casey Dugan, and Michelle Bachman. 2024.\nEmerging Reliance Behaviors in Human-AI Text Generation: Hallucinations, Data Quality Assessment, and Cognitive Forcing Functions. arXiv\npreprint arXiv:2409.08937 (2024).\n[5] Shraddha Barke, Michael B James, and Nadia Polikarpova. 2023. Grounded copilot: How programmers interact with code-generating models.\nProceedings of the ACM on Programming Languages 7, OOPSLA1 (2023), 85–111.\n[6] Brett A Becker, Michelle Craig, Paul Denny, Hieke Keuning, Natalie Kiesler, Juho Leinonen, Andrew Luxton-Reilly, James Prather, and Keith Quille.\n2023. Generative ai in introductory programming. Name of Journal (2023).\n[7] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the dangers of stochastic parrots: Can language\nmodels be too big?. In Proceedings of the 2021 ACM conference on fairness, accountability, and transparency. 610–623.\n[8] Zana Buçinca, Maja Barbara Malaya, and Krzysztof Z Gajos. 202"
    },
    {
      "rank": 6,
      "distance_l2": 0.7809937596321106,
      "source_id": "NoviceProgramming2024",
      "chunk_id": "NoviceProgramming2024_chunk_016",
      "text": " levels.\nThe significant findings from the Friedman test suggest that not only did students’\nsatisfaction improve over time, but the quality of their interactions with AI tools also likely\nimproved. Since the same AI model was used throughout the course, this trend indicates\nthat students became more adept at prompt engineering, enabling them to extract better\nresults from the AI tools for any topic, not only programming. Additionally, a majority\nof students reported switching to English as their prompt language, which could also\nprovide better results. These findings open up several areas for further discussion. First,\nthe improvement in satisfaction over time underscores the importance of practice and\nEduc. Sci. 2024, 14, 1089\n11 of 17\nexperience when using AI tools. As students became more proficient with the capabilities\nand limitations of these tools, they were able to craft better prompts, leading to more\nsatisfactory outcomes. This suggests that prompt engineering is a critical skill that can be\ndeveloped over time and should be an integral part of AI education. Therefore, teaching\nstudents how to effectively interact with AI tools can enhance their learning experiences, a\npoint that has not been extensively addressed in the prior literature.\nThe analysis of the fourth research question reveals a diverse range of applications\nfor AI tools in an introductory programming course. These findings suggest that novice\nprogramming teams are leveraging AI tools primarily to optimize and enhance their\ncoding processes, particularly in areas that require repetitive or detailed work, such as\ncommenting and debugging. The varied use of AI tools across different tasks also highlights\ntheir versatility and the teams’ growing confidence in incorporating these tools into various\naspects of their assignments as the course progresses.\nThe data indicates that, as the course demands increased, so did the reliance on\nAI tools for more complex tasks, reflecting a deeper integration of these tools into the\nprogramming workflow. This underscores the importance of AI tools as a valuable resource\nin programming education, particularly for tasks that can support learning and improve\ncode quality. However, it also raises questions about the potential for over-reliance and the\nneed to balance AI tool usage with the development of fundamental programming skills.\nThe analysis of the fifth research question, which explored the common benefits and\nconcerns students have regarding the use of AI tools in their studies, revealed a complex\ninterplay of advantages and challenges experienced by novice programmers. The most\nfrequently cited benefit was the provision of instant help and quick answers or explana-\ntions, mentioned by 79.4% of teams (58 teams). This was closely followed by assistance\nwith repetitive tasks, such as writing comments, reported by 75.3% of teams (55 teams).\nThis means that AI tools can minimize extraneous cognitive load by automating routine\ntasks, thereby enabling students to focus more effectively on mastering core programming\nprinciples. Immediate response and feedback from AI tools were valued by 57.5% of\nteams (42 teams), while help with identifying and correcting errors was acknowledged\nby 54.8% of teams (40 teams). Other notable benefits included access to diverse resources\nand additional examples (45.21%), spelling correction (23.3%), and translation between\nlanguages (19.2%). These findings are in line with Malinka et al. [22], who suggested\nthat ChatGPT could serve as a valuable aid in discussing challenges encountered during\nassignments"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2.5-testing_streamlit"
}