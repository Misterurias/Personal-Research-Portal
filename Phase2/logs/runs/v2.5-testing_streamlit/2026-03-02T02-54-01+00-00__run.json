{
  "timestamp": "2026-03-02T02:54:01+00:00",
  "query": "What risks or limitations of AI-assisted code generation are documented in the corpus?",
  "retrieval_query": "\"Risk and limitation documentation on AI-assisted code generation in academic corpus since 2010\"",
  "query_rewritten": true,
  "rewritten_query": "\"Risk and limitation documentation on AI-assisted code generation in academic corpus since 2010\"",
  "top_k": 7,
  "answer": "I can only answer based on the provided evidence chunks.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.6788943409919739,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_003",
      "text": "olve actual programming tasks in different languages and varying degrees of complexity, professional \ndevelopers of different skill and experience levels. Our assumption is that although the use of AI-assisted \ntools will increase productivity, at the same time, they might lead to the poor quality and insecure software \ndevelopment, which will need to be dealt with through proper industrial adoption strategies. \nResearch has contributed in three ways. To start with, the paper provided empirical evidence that through \nthe use of assistance from AI in code production, there was a significant impact on the software quality \nmetrics namely, cyclomatic complexity, maintainability index and code smell density. Next, the authors \nperformed a comprehensive examination of the security vulnerabilities related to AI-generated code in the \nvarious programming languages and projects. Finally, the research gives the software organizations that \nwant to use AI tools good insights and practices for risk reduction. Thus, the implications of our results \nare very important for the education of software engineers, the industry's practices and the direction of \nfuture research in the area of AI and software development. \n \n2. Literature Review \nThe areas where artificial intelligence and software engineering meet have become the center of a huge \nnumber of research studies, with code generation and program synthesis being the two main areas. The \nfirst automated code generation attempts relied on template-based methods and rule-based systems \nproducing the so-called boilerplate codes from high-level specifications [10]. The deep learning era totally \nchanged the picture, with the application of sequence-to-sequence models and recurrent neural networks \nto the code synthesis tasks [11]. The introduction of the transformer architectures was the turning point, \nwith models such as CodeBERT and GraphCodeBERT being able to perform on a par with the best \nmethods in the problem categories of code understanding and generation [12, 13]. \nRecently, the development of large language models has further changed the scenery in code generation. \nFor instance, GPT-3 showed outstanding learning ability through a few examples for programming tasks \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n3\n \n[14], while Codex, the engine behind GitHub Copilot, scored highly in competitive programming \nproblems [15]. The following studies have looked into the models' capabilities in various programming \nlanguages and difficult algorithms [16, 17]. \nThe findings of empirical studies of AI-assisted coding tools presented a somewhat mixed picture. Ziegler \net al. indicated that developers using GitHub Copilot completed assignments on average 55.8% more \nquickly and reported higher satisfaction [18]. In contrast, Sandoval et al. indicated that code assemblages \nby AI showed significantly higher vulnerabilities, especially to the integrity of verification of input and \ncryptographic processes [19]. Perry et al. raised concerns about issues of misunderstanding in cloning \nobfuscated code in libraries; licensing problems in open-source projects; and the potential for unnoticed \nsubtle logical problems in open-source projects [20]. \nThe issue of how to assess and ensure the quality of AI-generated code remains an open question in \nresearch. Old-fashioned software measurement techniques have yielded different results depending on the \ntools and programming"
    },
    {
      "rank": 2,
      "distance_l2": 0.6839169859886169,
      "source_id": "EnterpriseImpact2024",
      "chunk_id": "EnterpriseImpact2024_chunk_003",
      "text": " assistants can aid sensemaking tasks in code repositories.\n• We identify a shared responsibility between people and AI systems in mitigating the risks of generated outputs.\n2\nRelated Work\nWe outline three areas relevant to our study of AI code assistants: code-fluent LLMs and their incorporation into the\nsoftware engineering workflow; the multi-faceted nature of productivity in software engineering; and studies of AI\ncode assistants.\n2.1\nCode-fluent LLMs and software engineering assistants\nLarge language models that have been exposed to source code in their pre-training have demonstrated a high degree of\naptitude in performing a variety of tasks: converting natural language to code (e.g. [2, 16, 19, 56]), converting code\nto natural language documentation (e.g. [16, 31]) or explanations (e.g. [37]), and converting code to code, such as by\ntranslating it from one language to another (e.g. [2, 19, 46, 57]) or by creating unit tests (e.g. [48]). The introduction of\nthe Codex model [10] and its corresponding incorporation into software developers’ IDEs through GitHub Copilot6\ndemonstrated how code-fluent LLMs could revolutionize the software development workflow. New agentic design\npatterns are enabling coding assistants to perform even more complex tasks, such as converting issues into pull\nrequests [25] and new feature descriptions into specifications and implementation plans7.\n1In this paper, we use the term “developer” as a catch-all to cover individuals who perform code-related work, including software engineers, architects,\nand data scientists.\n2GitHub Copilot: https://github.com/features/copilot\n3Amazon Q Developer: https://aws.amazon.com/q/developer/\n4Gemini Code Assist: https://cloud.google.com/gemini/docs/codeassist/overview\n5watsonx Code Assistant: https://www.ibm.com/products/watsonx-code-assistant\n6GitHub Copilot: https://github.com/features/copilot\n7GitHub Copilot Workspace: https://githubnext.com/projects/copilot-workspace\nManuscript submitted to ACM\nExamining the Use and Impact of an AI Code Assistant on Dev. Productivity and Experience in the Enterprise\n3\n2.2\nSoftware engineering productivity\nProductivity in software engineering is a complex, multi-faceted construct [17, 47]. It is often assessed via objective\nmetrics of productivity that capture the ratio of output to effort [47] (e.g. lines of code over time [15], function points [30]),\nthe complexity of the software system [20, 33], or the presence of errors or defects [26]. However, Meyer et al. [34]\nconsiders “when software developers perceive themselves to be productive and... unproductive” [34, p.1] as an important\naspect of productivity.\nCheng et al. [11] outline a number of subjective and objective factors that impact developer productivity, including\ncode quality, technical debt, infrastructure tools and support, team communication, and organizational changes and\nprocesses. In addition, researchers have found correlations between subjective and objective productivity metrics, such\nas the acceptance rate of suggested code [62] and the number of source code files owned by a developer [40] being\ncorrelated with perceived productivity.\nThe comprehensive landscape of software engineering productivity"
    },
    {
      "rank": 3,
      "distance_l2": 0.7064356207847595,
      "source_id": "AIReview2025",
      "chunk_id": "AIReview2025_chunk_001",
      "text": "236 \nA Review of Research on AI-Assisted Code Generation and AI-\nDriven Code Review \nYuzhi Wang \nBeijing University of Technology, Beijing, China \nshenrenaisite@yeah.net \nAbstract. With the significant breakthroughs of deep learning technologies such as large language \nmodels (LLMs) in the field of code analysis, AI has evolved from an auxiliary tool to a key technology \nthat deeply participates in code optimization and resolving performance issues. As modern software \nsystem architectures become increasingly complex, the requirements for their performance have \nalso become more stringent. During the coding stage, developers find it difficult to effectively identify \nand resolve potential performance issues using traditional methods. This review focuses on the \napplication of artificial intelligence in two key areas: AI-assisted intelligent code generation and AI-\npovered code review. The review systematically analyzed the application of LLMs in software \ndevelopment, revealing a situation where efficiency gains coexist with quality challenges. In terms \nof code generation, models such as Code Llama and Copilot have significantly accelerated the \ndevelopment process. In the field of code review, AI can effectively handle code standards and low-\nseverity defects. However, in the future, this field still needs to address the issues of the reliability \nand security of the code generated by LLMs, as well as the insufficient explainability of the results of \nautomated performance analysis. The future research focus in this field lies in addressing issues \nsuch as the lack of interpretability and insufficient domain knowledge of LLMs. It is necessary to \nprioritize enhancing the reliability of AI recommendations and promoting the transformation of AI \nfrom an auxiliary tool to an intelligent Agent with self-repair capabilities, in order to achieve a truly \nefficient and secure human-machine collaboration paradigm. This article systematically reviews the \nrelevant progress, aiming to promote the transformation of software engineering from an artificial-\ndriven model to an AI-enhanced automated paradigm. It provides theoretical references for ensuring \nthe quality of backend code, improving product delivery speed, and enhancing system reliability. \nKeywords: AI; LLM; Code Generation; Code Review. \n1. Introduction \nRecently, the growing complexity of modern software applications has driven an increased \nemphasis on high-quality, maintainable source code, thereby heightening the difficulty for developers \nto write efficient and error-free code [1-3]. Therefore, there is an urgent need for a smarter approach \nto empover developers. The emergence of Artificial Intelligence has fundamentally transformed \nconventional approaches to code optimization and refactoring by introducing a new dimension of \nautomation [2]. A striking example is LLMs, which have exhibited remarkable potential in \nprogramming tasks [4], especially in code review [5] and code generation [6]. This review aims to \nsystematically review and analyze the current application status and research progress of AI in \nsoftware program development and code generation and review. The analysis focuses on two aspects: \none is AI-assisted intelligent code generation, and the other is AI-powered code review. Through in-\ndepth exploration of these cutting-edge studies, the value of this review lies in clarifying how AI can \nassist developers in performing more convenient programming tasks and enabling the early detection \nof program defects as well as the control of the root causes of performance issues. This not only \nsignificantly enhances the efficiency and code delivery speed of the development team, but more \nimportantly, it greatly improves the reliability and quality of"
    },
    {
      "rank": 4,
      "distance_l2": 0.7070534825325012,
      "source_id": "CopilotExperiment2023",
      "chunk_id": "CopilotExperiment2023_chunk_008",
      "text": " al. (2021). Evaluating large language\nmodels trained on code. arXiv preprint arXiv:2107.03374.\n[Finnie-Ansley et al., 2022] Finnie-Ansley, J., Denny, P., Becker, B. A., Luxton-Reilly, A., and\nPrather, J. (2022). The robots are coming: Exploring the implications of openai codex on\nintroductory programming. In Australasian Computing Education Conference, pages 10–19.\n[Klinova and Korinek, 2021] Klinova, K. and Korinek, A. (2021). Ai and shared prosperity. In\nProceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, pages 645–651.\n[Manning et al., 2022] Manning, S., Mishkin, P., Hadﬁeld, G., Eloundou, T., and Eisner, E.\n(2022). A research agenda for assessing the economic impacts of code generation models.\n9\n[Mozannar et al., 2022] Mozannar, H., Bansal, G., Fourney, A., and Horvitz, E. (2022). Read-\ning between the lines: Modeling user behavior and costs in ai-assisted programming. arXiv\npreprint arXiv:2210.14306.\n[Nguyen and Nadi, 2022] Nguyen, N. and Nadi, S. (2022). An empirical evaluation of github\ncopilot’s code suggestions. In Proceedings of the 19th International Conference on Mining\nSoftware Repositories, pages 1–5.\n[Raj and Seamans, 2018] Raj, M. and Seamans, R. (2018). Artiﬁcial intelligence, labor, pro-\nductivity, and the need for ﬁrm-level data. In The economics of artiﬁcial intelligence: An\nagenda, pages 553–565. University of Chicago Press.\n[Sandoval et al., 2022] Sandoval, G., Pearce, H., Nys, T., Karri, R., Dolan-Gavitt, B., and Garg,\nS. (2022). Security implications of large language model code assistants: A user study. arXiv\npreprint arXiv:2208.09727.\n[Vaithilingam et al., 2022] Vaithilingam, P., Zhang, T., and Glassman, E. L. (2022). Expec-\ntation vs. experience: Evaluating the usability of code generation tools powered by large\nlanguage models.\n[Zhang et al., 2022] Zhang, D., Maslej, N., Brynjolfsson, E., Etchemendy, J., Lyons, T.,\nManyika, J., Ngo, H., Niebles, J. C., Sellitto, M., Sakhaee, E., et al. (2022). The ai index\n2022 annual report. arXiv preprint arXiv:2205.03468.\n[Ziegler et al., 2022] Ziegler, A., Kalliamvakou, E., Li, X. A.,"
    },
    {
      "rank": 5,
      "distance_l2": 0.7080912590026855,
      "source_id": "EnterpriseImpact2024",
      "chunk_id": "EnterpriseImpact2024_chunk_023",
      "text": " vs. experience: Evaluating the usability of code generation tools\npowered by large language models. In Chi conference on human factors in computing systems extended abstracts. 1–7.\n[51] Dakuo Wang, Justin D Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, and Alexander Gray.\n2019. Human-AI collaboration in data science: Exploring data scientists’ perceptions of automated AI. Proceedings of the ACM on human-computer\ninteraction 3, CSCW (2019), 1–24.\nManuscript submitted to ACM\nExamining the Use and Impact of an AI Code Assistant on Dev. Productivity and Experience in the Enterprise\n13\n[52] Justin D Weisz, Michael Muller, Stephanie Houde, John Richards, Steven I Ross, Fernando Martinez, Mayank Agarwal, and Kartik Talamadupula.\n2021. Perfection not required? Human-AI partnerships in code translation. In Proceedings of the 26th International Conference on Intelligent User\nInterfaces. 402–412.\n[53] Justin D Weisz, Michael Muller, Steven I Ross, Fernando Martinez, Stephanie Houde, Mayank Agarwal, Kartik Talamadupula, and John T Richards.\n2022. Better together? an evaluation of ai-supported code translation. In Proceedings of the 27th International Conference on Intelligent User Interfaces.\n369–391.\n[54] Michel Wermelinger. 2023. Using github copilot to solve simple programming problems. In Proceedings of the 54th ACM Technical Symposium on\nComputer Science Education V. 1. 172–178.\n[55] Zhuohao Wu, Danwen Ji, Kaiwen Yu, Xianxu Zeng, Dingming Wu, and Mohammad Shidujaman. 2021. AI creativity and the human-AI co-creation\nmodel. In Human-Computer Interaction. Theory, Methods and Tools: Thematic Area, HCI 2021, Held as Part of the 23rd HCI International Conference,\nHCII 2021, Virtual Event, July 24–29, 2021, Proceedings, Part I 23. Springer, 171–190.\n[56] Frank F Xu, Bogdan Vasilescu, and Graham Neubig. 2022. In-ide code generation from natural language: Promise and challenges. ACM Transactions\non Software Engineering and Methodology (TOSEM) 31, 2 (2022), 1–47.\n[57] Zhen Yang, Fang Liu, Zhongxing Yu, Jacky Wai Keung, Jia Li, Shuo Liu, Yifan Hong, Xiaoxue Ma, Zhi Jin, and Ge Li. 2024. Exploring and unleashing\nthe power of large language models in automated code translation. Proceedings of the ACM on Software Engineering 1, FSE (2024), 1585–1608.\n[58] Burak Yetistiren, Isik Ozsoy, and Eray Tuzun. 2022. Assessing the quality of GitHub copilot’s code generation. In Proceedings of the 18th international\nconference on predictive models and data analytics in software engineering. 62–71.\n[59] Ramaz"
    },
    {
      "rank": 6,
      "distance_l2": 0.7261402606964111,
      "source_id": "CodeQualityComparison2023",
      "chunk_id": "CodeQualityComparison2023_chunk_001",
      "text": "Noname manuscript No.\n(will be inserted by the editor)\nEvaluating the Code Quality of AI-Assisted Code\nGeneration Tools: An Empirical Study on GitHub Copilot,\nAmazon CodeWhisperer, and ChatGPT\nBurak Yetiştiren · Işık Özsoy · Miray\nAyerdem · Eray Tüzün\nthe date of receipt and acceptance should be inserted later\nAbstract\nContext AI-assisted code generation tools have become increasingly prevalent in soft-\nware engineering, offering the ability to generate code from natural language prompts or\npartial code inputs. Notable examples of these tools include GitHub Copilot, Amazon\nCodeWhisperer, and OpenAI’s ChatGPT.\nObjective This study aims to compare the performance of these prominent code gen-\neration tools in terms of code quality metrics, such as Code Validity, Code Correctness,\nCode Security, Code Reliability, and Code Maintainability, to identify their strengths\nand shortcomings.\nMethod We assess the code generation capabilities of GitHub Copilot, Amazon Code-\nWhisperer, and ChatGPT using the benchmark HumanEval Dataset. The generated\ncode is then evaluated based on the proposed code quality metrics.\nResults Our analysis reveals that the latest versions of ChatGPT, GitHub Copilot,\nand Amazon CodeWhisperer generate correct code 65.2%, 46.3%, and 31.1% of the\ntime, respectively. In comparison, the newer versions of GitHub CoPilot and Amazon\nCodeWhisperer showed improvement rates of 18% for GitHub Copilot and 7% for\nBurak Yetiştiren\nBilkent University,\nE-mail: burakyetistiren@hotmail.com\nIşık Özsoy\nBilkent University,\nE-mail: ozsoyisik@gmail.com\nMiray Ayerdem\nBilkent University,\nE-mail: miray.ayerdem@ug.bilkent.edu.tr\nEray Tüzün\nBilkent University,\nE-mail: eraytuzun@cs.bilkent.edu.tr\narXiv:2304.10778v2  [cs.SE]  22 Oct 2023\n2\nBurak Yetiştiren et al.\nAmazon CodeWhisperer. The average technical debt, considering code smells, was\nfound to be 8.9 minutes for ChatGPT, 9.1 minutes for GitHub Copilot, and 5.6 minutes\nfor Amazon CodeWhisperer.\nConclusions This study highlights the strengths and weaknesses of some of the\nmost popular code generation tools, providing valuable insights for practitioners. By\ncomparing these generators, our results may assist practitioners in selecting the optimal\ntool for specific tasks, enhancing their decision-making process.\nKeywords ChatGPT, OpenAI, Amazon CodeWhisperer, GitHub Copilot, code\ngeneration, code completion, AI pair programmer, empirical study\n1 Introduction\nCode completion and generation tools are essential for enhancing programmers’ per-\nformance and output quality in software development. Omar et al. (2012) define code\ncompletion tools as tools that are offered in most editors, which list contextually-relevant\nvariables, fields, methods, types, and other code snippets in the form of a floating menu.\nBy exploring and making choices from this menu, developers can avoid frequent gram-\nmatical and logical errors, reduce redundant"
    },
    {
      "rank": 7,
      "distance_l2": 0.7342660427093506,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_014",
      "text": " 23.7% and a total increase in critical severity of 89%. We also demonstrate \nthat some dimensions of code quality are improved with AI-assisted code generation tools (i.e., \nmaintainability, cyclomatic complexity) but caution is warranted with operational risks, to code itself (i.e. \nextra code duplication) and security vulnerabilities. We also examined differences across programming \nlanguages, and in particular, we found that while using AI-assisted code generation technologies is \nconstructive in Python, it warrants heightened caution around codex in C++ (to name only one). Finally, \nwhile we examined experience differences, we found that junior developers require support to prevent \nexcessive dependency on AI and senior developers could receive the maximum benefit from an AI tool \nwhen used independently. The security findings are quite concerning, which suggests that the injection of \nvulnerabilities is potentially higher and the chances of being detected is lowered, thus introducing grave \nrisks for organizations. \nSoftware organizations need to introduce processes for security review, advanced training, and the use of \nautomated security analysis in order to recognize possible patterns related to AI-generated code. It is no \nlonger possible to assume AI-generated code is unsafe or that the software development processes you \nhave in place will contain the risks associated with using AI-generated code based on the evidence we \npresent. AI-generated code is a fundamentally transformative and irreversibly changing practice in the \nsoftware engineering of the discipline and the question is how we can achieve the benefit and reduce risk \nthrough additional empirical research and the introduction of specific practices for AI security while \ncontinuing to have experts who are humans. Our research offers organizations an evidence-based basis for \nthe implementation of the AI tool and provides a benchmark for future longitudinal research design of \nlong-term outcomes of the analysis of the argued effort of transformational technology for deployment. \n \n7. References \n1. Chen, M., Tworek, J., Jun, H., et al. (2024). Evaluating large language models trained on code. ACM \nTransactions on Software Engineering and Methodology, 33(4), 1-42. \n2. Barke, S., James, M. B., & Polikarpova, N. (2023). Grounded Copilot: How programmers interact \nwith code-generating models. Proceedings of the ACM on Programming Languages, 7(OOPSLA1), \n85-111. \n3. Vaithilingam, P., Zhang, T., & Glassman, E. L. (2024). Expectation vs. experience: Evaluating the \nusability of code generation tools powered by large language models. CHI Conference on Human \nFactors in Computing Systems, 1-23. \n4. Kalliamvakou, E., Bird, C., Zimmermann, T., et al. (2024). The impact of AI on developer \nproductivity: Evidence from GitHub Copilot. IEEE Software, 41(3), 34-42. \n5. Peng, S., Kalliamvakou, E., Cihon, P., & Demirer, M. (2023). The impact of AI on developer \nproductivity: Findings from a study of GitHub Copilot. arXiv preprint arXiv:2302.06590. \nInternational Journal for Multidisciplinary Research (IJFMR) \n \n"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2-trust-tightened-qrewrite"
}