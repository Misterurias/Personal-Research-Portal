{
  "timestamp": "2026-03-02T03:41:28+00:00",
  "query": "What evidence links AI coding tools to technical debt accumulation?",
  "retrieval_query": "\"evidence linking AI coding tools to technical debt accumulation\"",
  "query_rewritten": true,
  "rewritten_query": "\"evidence linking AI coding tools to technical debt accumulation\"",
  "top_k": 6,
  "answer": "According to the provided evidence chunks, here are the answers:\n\n**How does AI-assisted programming impact the development and maintenance activities and the technical debt of the OSS projects?**\n\nThe introduction of GitHub Copilot leads to increased code review and rework effort on PRs, indicating a greater reliance on expedient or insufficiently integrated solutions. This suggests that AI adoption may accelerate technical debt accumulation in OSS projects.\n\n**What are the three measures used to capture changes in code productivity after Copilot?**\n\nLines of code added, commits, and PRs submitted to the project are the measures used to capture changes in code productivity after Copilot.\n\n**How is technical debt measured at the project level using PR rework?**\n\nHigher levels of PR rework indicate greater reliance on expedient or insufficiently integrated solutions, reflecting the extent to which initially submitted contributions require modification before being integrated into the codebase.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.5997393727302551,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_008",
      "text": ". In other words, the ease of generating code masks\nunderlying structural and logical gaps that become apparent under expert scrutiny (Barrett et al. 2023). As\nwith other AI tools that create superficially polished but potentially shallow results, vibe coding may be\nappealing for rapid prototyping, yet the secondary effects that this may have on reliability or maintainability\nwhen applied to nontrivial software development tasks is an open question.\nOur study investigates this issue by analyzing how the adoption of GitHub Copilot reshapes contributor\neffort across production and maintenance activities, and whether it disproportionately shifts the burden of\nmaintenance onto a smaller group of core contributors.\n2.2.\nConceptualization of Technical Debt\nTechnical debt captures the intertemporal trade-off between short-term development speed and long-term\nsystem maintainability (Cunningham 1992). A growing body of research has established that technical debt\nis economically consequential, persistent, and shaped by organizational choices. Drawing on the informa-\ntion systems and computer science literature, we synthesize prior work in Table 1 and adopt a definition of\ntechnical debt in this study as accumulation of suboptimal code, design, or documentation decisions in PR\nprocess that increase PR Rework (technical debt) and PR Review (maintenance effort) - a definition that is\nparticularly prominent in the era of GenAI software development.\n7 https://stackoverflow.blog/2025/08/07/a-new-worst-coder-has-entered-the-chat-vibe-coding-without-code-knowledge/\n8 https://www.techradar.com/pro/security/curl-will-stop-bug-bounties-program-due-to-avalanche-of-ai-slop\n7\nMeasurement approaches for technical debt have evolved along two complementary axes. One strand\nemphasizes static code metrics (e.g., code complexity, duplication, test coverage) as proxies for debt accu-\nmulation, enabling automated detection and cross-project comparisons (Paramitha and Massacci 2023, Yoo\net al. 2025). Paramitha and Massacci (2023) show how dependency structures in open-source ecosystems\n(top 600 Python packages) amplify technical leverage, allowing localized weaknesses to propagate across\npackages. Yoo et al. (2025) similarly demonstrate that dependency network structures shape the diffusion\nof security vulnerabilities in software supply chains. Another strand operationalizes technical debt through\nprocess and outcome indicators—such as rework rates, defect density, time-to-merge, and maintenance\neffort—thereby connecting debt to developer behavior and organizational performance (Ramasubbu and\nKemerer 2016, Banker et al. 2021, Ramasubbu and Kemerer 2021). Both approaches have value: the former\nmetric-based techniques are scalable and actionable for tooling, while the later process indicators capture\nthe economic and human costs that managers and maintainers ultimately face.\nEmpirical studies across industry and OSS ecosystems consistently find that technical debt impairs long-\nrun productivity and increases maintenance burdens (Paramitha and Massacci 2023). Work in empirical\nsoftware engineering shows that higher measured debt correlates with increased bug rates, longer defect\nresolution times, and reduced velocity for feature delivery (Ramasubbu and Kemerer 2016). Rinta-Kahila\net al. (2023) further demonstrate that organizations can become “trapped”"
    },
    {
      "rank": 2,
      "distance_l2": 0.622990071773529,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_028",
      "text": "les and best practices, resulting in code that is functional but brittle. This concern echoes evidence\nfrom other AI-augmented work settings, where less-experienced workers experience large productivity\ngains while more skilled workers see modest improvements and increased coordination burdens (Brynjolf-\nsson et al. 2025). In OSS settings, these dynamics can further worsen technical debt by weakening the\nfeedback loop between contribution and learning.\nThese insights point to several directions for future research. Scholars could examine how different\nproject governance mechanisms moderate AI-induced technical debt, such as automated testing, mod-\nular architectures, or formalized review protocols. Future work may also explore heterogeneity across\nproject types, identifying which OSS projects are most vulnerable to debt accumulation under AI-assisted\ndevelopment. More broadly, the dynamics documented here may extend beyond OSS to other knowledge-\nintensive domains where AI increases output without replacing expert judgment. As OSS components are\nincreasingly embedded in enterprise systems and public infrastructure (Nagle 2019), understanding how AI\nreshapes technical debt dynamics becomes critical not only for OSS sustainability but for the resilience of\nthe broader digital ecosystem.\nAs a concluding remark, the challenges observed in OSS, such as quality concerns and increased main-\ntenance burdens driven by productivity gains among newer and less-experienced contributors, should serve\nas an early warning for similar risks in other knowledge-intensive domains where AI is being promoted to\nboost productivity and innovation.\n25\nReferences\nAngrist JD, Pischke JS (2009) Mostly Harmless Econometrics: An Empiricist’s Companion (Princeton University\nPress).\nBanker RD, Liang Y, Ramasubbu N (2021) Technical Debt and Firm Performance. Management Science 67(5):3174–\n3194.\nBarrett C, Boyd B, Bursztein E, Carlini N, Chen B, Choi J, Chowdhury AR, Christodorescu M, Datta A, Feizi S, et al.\n(2023) Identifying and Mitigating the Security Risks of Generative AI. Foundations and Trends® in Privacy and\nSecurity 6(1):1–52.\nBrown N, Cai Y, Guo Y, Kazman R, Kim M, Kruchten P, Lim E, MacCormack A, Nord R, Ozkaya I, Sangwan R,\nSeaman C, Sullivan K, Zazworka N (2010) Managing Technical Debt in Software-reliant Systems. Proceedings\nof the FSE/SDP Workshop on Future of Software Engineering Research, 47–52, FoSER ’10 (New York, NY,\nUSA: Association for Computing Machinery).\nBrynjolfsson E, Li D, Raymond LR (2025) Generative AI at Work. The Quarterly Journal of Economics 140(2):889—\n-942.\nChen Z, Chan J (2024) Large Language Model in Creative Work: The Role of Collaboration Modality and User\nExpertise. Management Science 70(12):9101–9117.\nCrowston K, Wei K, Li Q, Howison J (2006) Core and Periphery in Free/libre and Open Source Software Team Com-\nmunications. Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS’06),\nvolume 6,"
    },
    {
      "rank": 3,
      "distance_l2": 0.6483279466629028,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_026",
      "text": ". First, the introduction of GitHub Copilot leads to higher\ndevelopment activity at both the repository and individual levels, measured by commits and PR, consistent\nwith industry evidence on AI-driven productivity gains (Peng et al. 2023). Second, these gains are accompa-\nnied by a significant increase in maintenance-related activities, as AI-generated contributions require more\nrevisions before integration - an early indicator of technical debt accumulation. Third, the effects are highly\nheterogeneous: core contributors review more PRs, contribute fewer commits, and extend their mainte-\nnance responsibilities across a wider range of repositories, suggesting that AI-assisted contributions from\nperipheral developers increase coordination and review burdens.\nBy conceptualizing GenAI as an endogenous shock to software production, this study advances the tech-\nnical debt literature in several important ways. First, consistent with prior work linking technical debt to firm\nperformance (Banker et al. 2021) and remediation costs (Ramasubbu and Kemerer 2016, 2021), we demon-\nstrate that AI-assisted code increases realized remediation effort, measured through PR rework. Second, we\nshow that technical debt is increasingly an outdated workload distribution phenomenon: maintenance costs\nare concentrated among a shrinking pool of core contributors, whose own productive output declines as\nmaintenance demands rise. Third, our findings complement research on organizational design and auton-\nomy (Paramitha and Massacci 2023, Yoo et al. 2025) by revealing how technological change can exacerbate\nasymmetries in effort and responsibility, even when the OSS repository workflow remains unchanged.\n15 https://mashable.com/archive/heartbleed-bug-websites-affected\n23\nTo illustrate the scale of Copilot’s impact on OSS communities, Microsoft core contributors in our dataset\nconduct on average, 976 commits, 160 PRs, and 166 PR reviews annually before its introduction. The\nincreased volume of code associated with Copilot adoption results in an additional workload – each core\ncontributor is expected to review approximately 10 more PRs annually. This added maintenance burden\ncorresponds to a reduction of 164 commits and 9 PR contributions per year per core contributor. More\ncritically, GitHub’s 2024 surveys reveal that more than one-third of contributors to the 10 most popular OSS\nprojects made their first contribution after signing up for GitHub Copilot, highlighting a significant influx\nof new and often less experienced developers16.\nWith annual contributions to OSS projects approaching 1 billion, this surge in participation significantly\nincreases the burden on core contributors, who take on the maintenance related tasks in the project. As a\nresult, maintainers are compelled to reallocate their time toward reviewing and managing code submissions\ninstead of writing new code.\n7.2.\nContributions and Future Research\nExtant research on AI pair programming has primarily emphasized productivity and efficiency gains, sug-\ngesting that tools such as GitHub Copilot can substantially accelerate software development (Peng et al.\n2023). While these benefits are evident in our data, our findings reveal a more nuanced set of consequences.\nIn particular, we show that AI-assisted programming also amplifies software maintenance challenges, espe-\ncially for core contributors who bear responsibility for code review and integration. Our individual-level\nanalysis demonstrates that while less-experienced contributors increase their output, experienced"
    },
    {
      "rank": 4,
      "distance_l2": 0.6738855838775635,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_009",
      "text": " Ramasubbu and Kemerer 2021). Both approaches have value: the former\nmetric-based techniques are scalable and actionable for tooling, while the later process indicators capture\nthe economic and human costs that managers and maintainers ultimately face.\nEmpirical studies across industry and OSS ecosystems consistently find that technical debt impairs long-\nrun productivity and increases maintenance burdens (Paramitha and Massacci 2023). Work in empirical\nsoftware engineering shows that higher measured debt correlates with increased bug rates, longer defect\nresolution times, and reduced velocity for feature delivery (Ramasubbu and Kemerer 2016). Rinta-Kahila\net al. (2023) further demonstrate that organizations can become “trapped” in technical debt due to coor-\ndination failures, organizational inertia, and escalating switching costs. The introduction of GenAI tools\nsuch as GitHub Copilot represents a departure from these assumptions (Yeverechyahu et al. 2024). Unlike\nprior productivity-enhancing tools, GenAI dramatically lowers the marginal cost of producing code and\nreduces skill barriers to contribution (Peng et al. 2023). While prior studies document productivity gains\nfrom AI-assisted coding, they provide limited insight into how these gains translate into technical debt and\nmaintenance related challenges.\nFrom a technical debt perspective, GenAI may accelerate debt accumulation by increasing code volume\nwithout proportionate improvements in quality, the integration with the software, or architectural coher-\nence (Pimenova et al. 2025). By lowering the cost of producing code, AI-assisted programming encourages\nrapid iteration and experimentation, but can shift attention away from longer-term concerns such as main-\ntainability, readability, and alignment with existing system design (Barrett et al. 2023, Schreiber and Tippe\n2025). As a result, defects, inconsistencies, and design shortcuts may be introduced more quickly than\nthey can be identified and resolved. Over time, this imbalance can compound, transforming short-term pro-\nductivity gains into persistent maintenance obligations that must be absorbed by experienced developers\n(Eghbal 2020). While GenAI promises to enhance development speed and broaden participation, it may\nsimultaneously intensify the very technical debt that constrains system reliability, scalability, and long-run\nperformance (Ramasubbu and Kemerer 2021). If this logic is valid, we expect that GenAI may lead to a\ngreater accumulation of technical debt in OSS projects.\n8\nTable 1\nSelected Literature on Technical Debt and Software Maintenance\nStudy\nContext\nMethod\nMeasurement\nKey Findings\nBanker et al.\n(2021)\nCustomer\nrelationship\nmanagement\n(CRM)\nsystems in 26 firms\nEconometric analysis\nPercentage of customized codes in the\nCRM system that do not adhere to vendor-\nprescribed standard\nHigher technical debt is associated\nwith\nlower\nfirm\nperformance\nand\nreduced operational efficiency over\ntime.\nRamasubbu\n&\nKemerer\n(2021)\nOutsourced Commercial\nOff-The-Shelf\n(COT)\nenterprise systems\nEconometric analysis\nViolations of the design and programming\nstandards established by the vendor of the\nCOTS enterprise system\nActive remediation policies reduce\nlong-term\nmaintenance\ncosts,\nbut\nexcessive deferral leads to escalating\ntechnical debt.\nRamas"
    },
    {
      "rank": 5,
      "distance_l2": 0.6927672624588013,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_031",
      "text": "Peng S, Kalliamvakou E, Cihon P, Demirer M (2023) The Impact of AI on Developer Productivity: Evidence from\nGithub Copilot. arXiv preprint arXiv:2302.06590 .\nPimenova V, Fakhoury S, Bird C, Storey MA, Endres M (2025) Good Vibrations? A Qualitative Study of Co-Creation,\nCommunication, Flow, and Trust in Vibe Coding. arXiv preprint arXiv:2509.12491 .\nRamasubbu N, Kemerer CF (2016) Technical Debt and the Reliability of Enterprise Software Systems: A Competing\nRisks Analysis. Management Science 62(5):1487–1510.\nRamasubbu N, Kemerer CF (2021) Controlling Technical Debt Remediation in Outsourced Enterprise Systems Main-\ntenance: An Empirical Analysis. Journal of Management Information Systems 38(1):4–28.\n27\nRinta-Kahila T, Penttinen E, Lyytinen K (2023) Getting Trapped in Technical Debt: Sociotechnical Analysis of a\nLegacy System’s Replacement. MIS Quarterly 47(1):1–32.\nRoberts JA, Hann IH, Slaughter SA (2006) Understanding the Motivations, Participation, and Performance of Open\nSource Software Developers: A Longitudinal Study of the Apache Projects. Management Science 52(7):984–\n999.\nRodriguez M (2023) Research: Quantifying GitHub Copilot’s Impact on Code Quality - The GitHub Blog. URL\nhttps://github.blog/2023-10-10-research-quantifying-github-copilots-impact-on-code-quality/.\nRullani F, Haefliger S (2013) The Periphery on Stage: The Intra-organizational Dynamics in Online Communities of\nCreation. Research Policy 42(4):941–953.\nSchreiber M, Tippe P (2025) Security Vulnerabilities in AI-Generated Code: A Large-Scale Analysis of Public GitHub\nRepositories, 153–172 (Springer Nature Singapore).\nSetia P, Rajagopalan B, Sambamurthy V, Calantone R (2012) How Peripheral Developers Contribute to Open-Source\nSoftware Development. Information Systems Research 23(1):144–163.\nSong F, Agarwal A, Wen W (2024) The Impact of Generative AI on Collaborative Open-Source Software Develop-\nment: Evidence from GitHub Copilot. arXiv preprint arXiv:2410.02091 .\nVaccaro M, Almaatouq A, Malone T (2024) When Combinations of Humans and AI are Useful: A Systematic Review\nand Meta-Analysis. Nature Human Behaviour 8(12):2293–2303.\nvon Hippel E, von Krogh G (2003) Open Source Software and the “Private-Collective” Innovation Model: Issues for\nOrganization Science. Organization Science 14(2):209–223.\nWilliams-Ceci S, Jakesch M, Bhat A, Kadoma K, Zalmanson L, Naaman M (2025) Biased AI Writing Assistants Shift\nUsers’ Att"
    },
    {
      "rank": 6,
      "distance_l2": 0.7774320840835571,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_004",
      "text": "1, Ramasubbu and Kemerer 2021). These maintenance tasks are generally less intrinsically driven and\ntypically assigned to contributors who possess both technical expertise and trust of the community to ensure\nthe quality and reliability of the codebase (Medappa et al. 2023, Eghbal 2020). Thus, we seek to answer the\nquestion: How does AI-assisted programming impact the development and maintenance activities and the\ntechnical debt of the OSS projects?\nIn this study, we examine whether technical debt and maintenance efforts of OSS projects changed after\nthe introduction of GitHub Copilot through increased code review and rework effort on PRs. To empirically\ntest this, we exploit the release of GitHub Copilot as a technical preview in June 2021, which included lim-\nited programming language endorsement. We focus on OSS projects owned by Microsoft, as the company\nhad exclusive access to OpenAI’s GPT-3, the model powering GitHub Copilot during its technical preview,\ndue to its investment in OpenAI and its prior acquisition of GitHub.4,5 The individual users in our dataset\nare contributors to Microsoft-owned OSS projects. We estimate the effect of Copilot at both the project\nand contributor levels using a Difference-in-Differences (DiD) design. Treatment and control groups were\ndefined based on the primary programming language: those using Copilot-endorsed languages formed the\ntreatment group, while non-endorsed language users served as the control (Yeverechyahu et al. 2024). For\nboth project and contributor levels, we collected data on programming activities and aggregated them at the\nmonthly level.\nWe examine the changes in code productivity after Copilot by three measures: lines of code added,\ncommits 6 and PRs submitted to the project. To capture the secondary effects of AI adoption on technical\ndebt and maintenance effortsof OSS communities, we focused on two complementary outcomes. First, we\n4 https://www.technologyreview.com/2020/09/23/1008729/openai-is-giving-microsoft-exclusive-access-to-its-gpt-3-language-\nmodel/\n5 https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/thomas-dohmke-on-improving-\nengineering-experience-using-generative-ai\n6 A commit is the fundamental unit of change on GitHub. Similar to saving a file that’s been edited, a commit records changes to\none or more files on GitHub - https://docs.github.com/en/pull-requests/committing-changes-to-your-project/creating-and-editing-\ncommits/about-commits\n4\nmeasured technical debt at the project level using PR rework, which reflects the extent to which initially\nsubmitted contributions require modification before being integrated into the codebase (Ramasubbu and\nKemerer 2016, 2021). Higher levels of rework indicate greater reliance on expedient or insufficiently inte-\ngrated solutions. Second, we measured maintenance effort at the individual level using PR reviews, which\ncapture the time and effort required from contributors to evaluate, correct, and integrate submitted code\n(Medappa et al. 2023).\nBased on our analysis of a large-scale panel dataset from GitHub, we find that while AI adoption leads to\nproductivity gains, they also increase maintenance-related activities"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2.5-testing_streamlit"
}