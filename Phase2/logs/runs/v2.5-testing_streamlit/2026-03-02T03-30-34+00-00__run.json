{
  "timestamp": "2026-03-02T03:30:34+00:00",
  "query": "What risks or limitations of AI-assisted code generation are documented in the corpus?",
  "retrieval_query": "risk limitations AI-assisted code generation documented 2010-present",
  "query_rewritten": true,
  "rewritten_query": "risk limitations AI-assisted code generation documented 2010-present",
  "top_k": 8,
  "answer": "Based on the provided evidence chunks, here are some answers:\n\n**How does AI-assisted intelligent code generation work?**\n\nAccording to \"AI-Assisted Intelligent Code Generation\" (Section 2.1), code generation is an automated process that converts structured or unstructured input information into source code. Large Language Models (LLMs) like Codex and Copilot play a crucial role in this process by breaking down tasks, storing data with long-term and short-term memories, and invoking external tools.\n\n**What are the limitations of AI-generated code?**\n\nAccording to \"Performance Analysis 2026\" (Section 3), one limitation of AI-generated code is that it may not fully grasp the developer's performance goals, potentially leading to code that prioritizes functionality over efficiency. Additionally, training data for code generation models might not explicitly emphasize performance considerations, impacting the models' ability to generate efficient code.\n\n**How do we evaluate the performance of AI-generated code?**\n\nAccording to \"Performance Analysis 2026\" (Section 3), we employ two strategies to evaluate the performance of AI-generated code: static performance regression analysis using industry-standard tools like Spotbugs and PMD, and dynamic performance regression analysis by comparing generated code with canonical solutions from datasets like HumanEval and MBPP.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.5763983130455017,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_003",
      "text": "olve actual programming tasks in different languages and varying degrees of complexity, professional \ndevelopers of different skill and experience levels. Our assumption is that although the use of AI-assisted \ntools will increase productivity, at the same time, they might lead to the poor quality and insecure software \ndevelopment, which will need to be dealt with through proper industrial adoption strategies. \nResearch has contributed in three ways. To start with, the paper provided empirical evidence that through \nthe use of assistance from AI in code production, there was a significant impact on the software quality \nmetrics namely, cyclomatic complexity, maintainability index and code smell density. Next, the authors \nperformed a comprehensive examination of the security vulnerabilities related to AI-generated code in the \nvarious programming languages and projects. Finally, the research gives the software organizations that \nwant to use AI tools good insights and practices for risk reduction. Thus, the implications of our results \nare very important for the education of software engineers, the industry's practices and the direction of \nfuture research in the area of AI and software development. \n \n2. Literature Review \nThe areas where artificial intelligence and software engineering meet have become the center of a huge \nnumber of research studies, with code generation and program synthesis being the two main areas. The \nfirst automated code generation attempts relied on template-based methods and rule-based systems \nproducing the so-called boilerplate codes from high-level specifications [10]. The deep learning era totally \nchanged the picture, with the application of sequence-to-sequence models and recurrent neural networks \nto the code synthesis tasks [11]. The introduction of the transformer architectures was the turning point, \nwith models such as CodeBERT and GraphCodeBERT being able to perform on a par with the best \nmethods in the problem categories of code understanding and generation [12, 13]. \nRecently, the development of large language models has further changed the scenery in code generation. \nFor instance, GPT-3 showed outstanding learning ability through a few examples for programming tasks \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n3\n \n[14], while Codex, the engine behind GitHub Copilot, scored highly in competitive programming \nproblems [15]. The following studies have looked into the models' capabilities in various programming \nlanguages and difficult algorithms [16, 17]. \nThe findings of empirical studies of AI-assisted coding tools presented a somewhat mixed picture. Ziegler \net al. indicated that developers using GitHub Copilot completed assignments on average 55.8% more \nquickly and reported higher satisfaction [18]. In contrast, Sandoval et al. indicated that code assemblages \nby AI showed significantly higher vulnerabilities, especially to the integrity of verification of input and \ncryptographic processes [19]. Perry et al. raised concerns about issues of misunderstanding in cloning \nobfuscated code in libraries; licensing problems in open-source projects; and the potential for unnoticed \nsubtle logical problems in open-source projects [20]. \nThe issue of how to assess and ensure the quality of AI-generated code remains an open question in \nresearch. Old-fashioned software measurement techniques have yielded different results depending on the \ntools and programming"
    },
    {
      "rank": 2,
      "distance_l2": 0.6350065469741821,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_014",
      "text": " 23.7% and a total increase in critical severity of 89%. We also demonstrate \nthat some dimensions of code quality are improved with AI-assisted code generation tools (i.e., \nmaintainability, cyclomatic complexity) but caution is warranted with operational risks, to code itself (i.e. \nextra code duplication) and security vulnerabilities. We also examined differences across programming \nlanguages, and in particular, we found that while using AI-assisted code generation technologies is \nconstructive in Python, it warrants heightened caution around codex in C++ (to name only one). Finally, \nwhile we examined experience differences, we found that junior developers require support to prevent \nexcessive dependency on AI and senior developers could receive the maximum benefit from an AI tool \nwhen used independently. The security findings are quite concerning, which suggests that the injection of \nvulnerabilities is potentially higher and the chances of being detected is lowered, thus introducing grave \nrisks for organizations. \nSoftware organizations need to introduce processes for security review, advanced training, and the use of \nautomated security analysis in order to recognize possible patterns related to AI-generated code. It is no \nlonger possible to assume AI-generated code is unsafe or that the software development processes you \nhave in place will contain the risks associated with using AI-generated code based on the evidence we \npresent. AI-generated code is a fundamentally transformative and irreversibly changing practice in the \nsoftware engineering of the discipline and the question is how we can achieve the benefit and reduce risk \nthrough additional empirical research and the introduction of specific practices for AI security while \ncontinuing to have experts who are humans. Our research offers organizations an evidence-based basis for \nthe implementation of the AI tool and provides a benchmark for future longitudinal research design of \nlong-term outcomes of the analysis of the argued effort of transformational technology for deployment. \n \n7. References \n1. Chen, M., Tworek, J., Jun, H., et al. (2024). Evaluating large language models trained on code. ACM \nTransactions on Software Engineering and Methodology, 33(4), 1-42. \n2. Barke, S., James, M. B., & Polikarpova, N. (2023). Grounded Copilot: How programmers interact \nwith code-generating models. Proceedings of the ACM on Programming Languages, 7(OOPSLA1), \n85-111. \n3. Vaithilingam, P., Zhang, T., & Glassman, E. L. (2024). Expectation vs. experience: Evaluating the \nusability of code generation tools powered by large language models. CHI Conference on Human \nFactors in Computing Systems, 1-23. \n4. Kalliamvakou, E., Bird, C., Zimmermann, T., et al. (2024). The impact of AI on developer \nproductivity: Evidence from GitHub Copilot. IEEE Software, 41(3), 34-42. \n5. Peng, S., Kalliamvakou, E., Cihon, P., & Demirer, M. (2023). The impact of AI on developer \nproductivity: Findings from a study of GitHub Copilot. arXiv preprint arXiv:2302.06590. \nInternational Journal for Multidisciplinary Research (IJFMR) \n \n"
    },
    {
      "rank": 3,
      "distance_l2": 0.6441392302513123,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_011",
      "text": " Interpretation of Findings \nThe findings from this research reveal a complicated trade-off landscape in AI-assisted code generation, \nwhich challenges simplistic narrative accounts focused explicitly on productivity. The 31.4% productivity \nincrease is consistent with claims made by practitioners in the field, yet we observe that our results \nhighlight previously under-documented security concerns; further, this demonstrates an inherently basic \ntension associated with our fountain of AI-assisted software engineering: while speed may be enhanced, \nthere are potential security and maintainability trade-offs for future versions of AI-assisted software. The \nparticular performance of particular programming languages might also be providing data interpretations \nthat leave something to be desired: the improved results for Python programming likely derived from the \nnature of the system training data and (possible) simpler syntax; meanwhile, the poorly rated secure \ncomputing of C++ largely reflects the complexity of memory management and constraints on how the \nprobability model encodes security. \nGiven the 89% increase in critical security vulnerabilities, it is an urgent concern, and it is caused by three \nfactors: AI models reproducing vulnerability patterns from the training data, developers not applying \nsufficient amount of security scrutiny to AI-generated code, and current AI models do not understand \nsecurity context and threat models. In fact, the finding that 76% of vulnerabilities in AI-generated code \nwere missed was a dangerous mixing of increased creation of vulnerabilities while decreasing \nvulnerability detection. The cognitive load results presented a clear paradox of decreased mental demand \nand increased frustration, as this reflected a qualitatively different cognitive demand. AI tools do decrease \ncognitive load for syntactic recall and boilerplate generation but introduce new cognitive demands related \nto prompt engineering, evaluating the suggestions, and correcting errors; and the frustration likely captures \ndeveloper's struggle with incorrect or false suggestions and the cognitive dissonance of evaluating code \nthat was not conceptualized by themselves. \n5.2 Implications for Practice \nSoftware organizations leveraging AI-assisted coding tools must have in place a variety of mitigation \nmechanisms including security review processes that are mandatory for AI-generated code concentrating \non the security issues that have been detected, security training that is improved by stressing the limitations \nof AI code, the use of SAST instruments that are integrated with AI-specific rule sets, and the creation of \norganizational regulations that define the appropriate use of AI assistance and manual implementation. \nThe deployment of AI tools should be done in different ways depending on the seniority level of \ndevelopers. Junior developers should be provided with additional support and guidance so that they do not \nbecome overly dependent on the tool and their skills are fostered, whereas senior developers should be \ngiven the freedom to use the tool for validation purposes which is linked to the best results. Companies \nshould pay for extensive training courses instead of expecting instant productivity increases because, \naccording to our findings, developers need experience equivalent to 3-4 tasks to reach their maximum \nperformance. Training should focus on the skills necessary to critically evaluate AI suggestions, prompt \nengineering, and being security-aware in order to get the most benefits and the least risks. \n \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7,"
    },
    {
      "rank": 4,
      "distance_l2": 0.6477867960929871,
      "source_id": "AIReview2025",
      "chunk_id": "AIReview2025_chunk_001",
      "text": "236 \nA Review of Research on AI-Assisted Code Generation and AI-\nDriven Code Review \nYuzhi Wang \nBeijing University of Technology, Beijing, China \nshenrenaisite@yeah.net \nAbstract. With the significant breakthroughs of deep learning technologies such as large language \nmodels (LLMs) in the field of code analysis, AI has evolved from an auxiliary tool to a key technology \nthat deeply participates in code optimization and resolving performance issues. As modern software \nsystem architectures become increasingly complex, the requirements for their performance have \nalso become more stringent. During the coding stage, developers find it difficult to effectively identify \nand resolve potential performance issues using traditional methods. This review focuses on the \napplication of artificial intelligence in two key areas: AI-assisted intelligent code generation and AI-\npovered code review. The review systematically analyzed the application of LLMs in software \ndevelopment, revealing a situation where efficiency gains coexist with quality challenges. In terms \nof code generation, models such as Code Llama and Copilot have significantly accelerated the \ndevelopment process. In the field of code review, AI can effectively handle code standards and low-\nseverity defects. However, in the future, this field still needs to address the issues of the reliability \nand security of the code generated by LLMs, as well as the insufficient explainability of the results of \nautomated performance analysis. The future research focus in this field lies in addressing issues \nsuch as the lack of interpretability and insufficient domain knowledge of LLMs. It is necessary to \nprioritize enhancing the reliability of AI recommendations and promoting the transformation of AI \nfrom an auxiliary tool to an intelligent Agent with self-repair capabilities, in order to achieve a truly \nefficient and secure human-machine collaboration paradigm. This article systematically reviews the \nrelevant progress, aiming to promote the transformation of software engineering from an artificial-\ndriven model to an AI-enhanced automated paradigm. It provides theoretical references for ensuring \nthe quality of backend code, improving product delivery speed, and enhancing system reliability. \nKeywords: AI; LLM; Code Generation; Code Review. \n1. Introduction \nRecently, the growing complexity of modern software applications has driven an increased \nemphasis on high-quality, maintainable source code, thereby heightening the difficulty for developers \nto write efficient and error-free code [1-3]. Therefore, there is an urgent need for a smarter approach \nto empover developers. The emergence of Artificial Intelligence has fundamentally transformed \nconventional approaches to code optimization and refactoring by introducing a new dimension of \nautomation [2]. A striking example is LLMs, which have exhibited remarkable potential in \nprogramming tasks [4], especially in code review [5] and code generation [6]. This review aims to \nsystematically review and analyze the current application status and research progress of AI in \nsoftware program development and code generation and review. The analysis focuses on two aspects: \none is AI-assisted intelligent code generation, and the other is AI-powered code review. Through in-\ndepth exploration of these cutting-edge studies, the value of this review lies in clarifying how AI can \nassist developers in performing more convenient programming tasks and enabling the early detection \nof program defects as well as the control of the root causes of performance issues. This not only \nsignificantly enhances the efficiency and code delivery speed of the development team, but more \nimportantly, it greatly improves the reliability and quality of"
    },
    {
      "rank": 5,
      "distance_l2": 0.684583842754364,
      "source_id": "EmpiricalToolAnalysis2025",
      "chunk_id": "EmpiricalToolAnalysis2025_chunk_001",
      "text": "International Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website: www.ijfmr.com       ●   Email: editor@ijfmr.com \n \nIJFMR250661350 \nVolume 7, Issue 6, November-December 2025 \n1\n \nEmpirical Analysis of AI-Assisted Code \nGeneration Tools: Impact on Code Quality, \nSecurity and Developer Productivity \n \nMrs. Purvi Sankhe1, Dr. Neeta Patil2, Mrs. Minakshi Ghorpade 3,  \nMrs. Pratibha Prasad4, Mrs. Monisha Linkesh5 \n \n2Associate Professor, IT Department, Thakur College of Engineering and Technology, Mumbai India \n1,3,4,5Assistant Professor, IT Department, Thakur College of Engineering and Technology, Mumbai India \n \nAbstract \nAI-assisted code generation tools have been the main cause of the increase in practices like code \ncompletion, bug fixing, and documentation among developers. However, the main concern regarding their \neffects on code quality, security vulnerabilities, and developer productivity still lacks empirical evidence. \nObjective: This study conducts an empirical assessment of the AI-assisted code generation tools' \neffectiveness in terms of software quality metrics, security vulnerability introduction, and developer \nproductivity, depending on the programming languages and project complexities. Methodology: A \ncontrolled experiment was performed with 120 professional developers where they were divided into \nexperimental and control groups and 480 code modules were analyzed among Python, Java, JavaScript, \nand C++ projects. Cyclomatic complexity, maintainability index, and code smell density were the three \nparameters for measuring code quality. Static analysis tools were employed in the evaluation of security \nvulnerabilities, while productivity was gauged through measuring task completion time and conducting \ncognitive load surveys. Results: The use of AI-assistive tools lead to a 31.4% increase in average developer \nproductivity; however, 23.7% more security vulnerabilities were introduced in the codes generated. Code \nmaintainability went up 18.2%, while cyclomatic complexity decreased by 14.6%. The variations in \nprogramming languages were significant, with Python being the one that realized the highest quality \nimprovement (26.3%) and C++ the one that faced the most security risk increase (34.8%). \n \nKeywords: Large language models, Software security, Static code analysis, Cyclomatic complexity. \n \n1. Introduction \nThe software engineering landscape has been drastically changed by the integration of artificial \nintelligence and machine learning technologies into development environments. AI-assisted code \ngeneration tools, which are based on huge language models that have been trained with billions of lines \nof code, have been identified as the most powerful of the innovative technologies that will significantly \ncontribute to the developer's productivity, lessening of cognitive burden, and speeding up of software \ndelivery cycles [1, 2]. In this manner interaction with such tools as GitHub Copilot, Amazon \nCodeWhisperer, and ChatGPT-based coding assistants radically changes the way developers write and \nmaintain software since they all provide real-time code suggestions, automated bug fixes, and intelligent \nInternational Journal for Multidisciplinary Research (IJFMR) \n \nE-ISSN: 2582-2160   ●   Website:"
    },
    {
      "rank": 6,
      "distance_l2": 0.6974886655807495,
      "source_id": "CodeQualityComparison2023",
      "chunk_id": "CodeQualityComparison2023_chunk_001",
      "text": "Noname manuscript No.\n(will be inserted by the editor)\nEvaluating the Code Quality of AI-Assisted Code\nGeneration Tools: An Empirical Study on GitHub Copilot,\nAmazon CodeWhisperer, and ChatGPT\nBurak Yetiştiren · Işık Özsoy · Miray\nAyerdem · Eray Tüzün\nthe date of receipt and acceptance should be inserted later\nAbstract\nContext AI-assisted code generation tools have become increasingly prevalent in soft-\nware engineering, offering the ability to generate code from natural language prompts or\npartial code inputs. Notable examples of these tools include GitHub Copilot, Amazon\nCodeWhisperer, and OpenAI’s ChatGPT.\nObjective This study aims to compare the performance of these prominent code gen-\neration tools in terms of code quality metrics, such as Code Validity, Code Correctness,\nCode Security, Code Reliability, and Code Maintainability, to identify their strengths\nand shortcomings.\nMethod We assess the code generation capabilities of GitHub Copilot, Amazon Code-\nWhisperer, and ChatGPT using the benchmark HumanEval Dataset. The generated\ncode is then evaluated based on the proposed code quality metrics.\nResults Our analysis reveals that the latest versions of ChatGPT, GitHub Copilot,\nand Amazon CodeWhisperer generate correct code 65.2%, 46.3%, and 31.1% of the\ntime, respectively. In comparison, the newer versions of GitHub CoPilot and Amazon\nCodeWhisperer showed improvement rates of 18% for GitHub Copilot and 7% for\nBurak Yetiştiren\nBilkent University,\nE-mail: burakyetistiren@hotmail.com\nIşık Özsoy\nBilkent University,\nE-mail: ozsoyisik@gmail.com\nMiray Ayerdem\nBilkent University,\nE-mail: miray.ayerdem@ug.bilkent.edu.tr\nEray Tüzün\nBilkent University,\nE-mail: eraytuzun@cs.bilkent.edu.tr\narXiv:2304.10778v2  [cs.SE]  22 Oct 2023\n2\nBurak Yetiştiren et al.\nAmazon CodeWhisperer. The average technical debt, considering code smells, was\nfound to be 8.9 minutes for ChatGPT, 9.1 minutes for GitHub Copilot, and 5.6 minutes\nfor Amazon CodeWhisperer.\nConclusions This study highlights the strengths and weaknesses of some of the\nmost popular code generation tools, providing valuable insights for practitioners. By\ncomparing these generators, our results may assist practitioners in selecting the optimal\ntool for specific tasks, enhancing their decision-making process.\nKeywords ChatGPT, OpenAI, Amazon CodeWhisperer, GitHub Copilot, code\ngeneration, code completion, AI pair programmer, empirical study\n1 Introduction\nCode completion and generation tools are essential for enhancing programmers’ per-\nformance and output quality in software development. Omar et al. (2012) define code\ncompletion tools as tools that are offered in most editors, which list contextually-relevant\nvariables, fields, methods, types, and other code snippets in the form of a floating menu.\nBy exploring and making choices from this menu, developers can avoid frequent gram-\nmatical and logical errors, reduce redundant"
    },
    {
      "rank": 7,
      "distance_l2": 0.7159897089004517,
      "source_id": "AIReview2025",
      "chunk_id": "AIReview2025_chunk_002",
      "text": "5] and code generation [6]. This review aims to \nsystematically review and analyze the current application status and research progress of AI in \nsoftware program development and code generation and review. The analysis focuses on two aspects: \none is AI-assisted intelligent code generation, and the other is AI-powered code review. Through in-\ndepth exploration of these cutting-edge studies, the value of this review lies in clarifying how AI can \nassist developers in performing more convenient programming tasks and enabling the early detection \nof program defects as well as the control of the root causes of performance issues. This not only \nsignificantly enhances the efficiency and code delivery speed of the development team, but more \nimportantly, it greatly improves the reliability and quality of the final software program [7], thereby \nreducing operational costs and driving the entire software engineering field towards a higher-level \nintelligent-assisted development paradigm. \n237 \n2. Literature Review \nIn recent years, the field of software engineering has developed rapidly. Software engineering \nencompasses the systematic and controlled design, development, maintenance, implementation and \nevolution of software systems [1]. As artificial intelligence has become a highly popular field at \npresent, it has also become a new component of software engineering [8]. To assist in software \ndevelopment, AI is now widely used in scenarios such as code generation and code review [9]. In \nparticular, large language models, as the latest breakthrough in the field of natural language \nprocessing in AI, have made particularly significant contributions to software development. LLM \nmainly employs the Transformer model as its core architecture. The LLM, which is built on large \ndatasets and advanced neural network architectures, demonstrates extremely high comprehension \ncapabilities, bringing about significant breakthroughs and possibilities to the field of software \ndevelopment [10]. For instance, models such as Codex [11], StarCode [12], Incoder [13], and Code \nLlama [14], Copilot[15]can all generate code with efficiency and accuracy comparable to that of \ndevelopers. These LLMs not only have extremely high efficiency but also excellent quality in code \nreview [10].  \n2.1 AI-Assisted Intelligent Code Generation \nCode generation is an automated process that converts structured or unstructured input information \n(such as natural language requirements descriptions, design documents, code snippets, etc.) into \nsource code. Its essence is to reflect the abstract intentions and task goals of the developers into \nspecific programming projects [16]. And based on LLM (Large Language Model) for code generation, \nby breaking down the tasks, having data storage with long-term and short-term memories, as well as \nthe invocation of external tools, these are currently important technical supports in the field of code \ngeneration [16]. This section will summarize the application effects and code generation quality of \nCodex and Copilot in the field of code generation. \n2.1.1 Code Llama \nThe Code Llama model series released by Meta AI focuses on code generation through long \nsequence contexts and instruction fine-tuning, and its mechanism is of great significance for the \ngeneration of complex logic at the back end [14]. \n2.1.1.1 Strong Context-Dependent and Long Sequence Processing Capabilities \nModern backend development typically involves complex distributed systems and microservice \narchitectures, and code generation must take into account global dependencies and architectural \nspecifications. Code L"
    },
    {
      "rank": 8,
      "distance_l2": 0.7401756048202515,
      "source_id": "PerformanceAnalysis2026",
      "chunk_id": "PerformanceAnalysis2026_chunk_015",
      "text": " has focused on evaluating the correctness and security \nof AI-generated code, performance regression has received less attention. However, intui­\ntively, AI-generated code models may not fully grasp the developer’s performance goals, \npotentially leading to code that prioritizes functionality over efficiency. On the other hand, \ntraining data for code generation models might not explicitly emphasize performance con­\nsiderations, impacting the models’ ability to generate efficient code. Given these potential \nshortcomings, it’s crucial to investigate the prevalence of performance regressions in AI-\ngenerated code. Understanding the scope of this issue will inform future research directions \nand development efforts for AI-assisted coding tools and code generation models.\nApproach  Our approach involves two strategies to evaluate the performance of AI-gener­\nated code. In particular, for static performance regression analysis, we employ industry-\nstandard tools, i.e., Spotbugs and PMD, to scan the generated Java code in the AixBench \ndataset. These tools are equipped with pre-defined rules that can detect performance regres­\nsions within the code. The detailed configuration of these rules is available in the replication \npackage we provided. For Python code in the HumanEval, MBPP, and EvalPerf datasets, \nwe use Qodana, a cloud-based static analysis platform, to identify potential performance \nregressions specific to Python code. To facilitate efficient analysis, we create new proj­\nects and establish a dedicated scan workflow within Qodana Cloud. This workflow enables \nQodana to automatically identify and highlight potential performance-related code issues \nwithin the generated Python code.\nFor dynamic performance regression analysis, we compare the generated code with \ncanonical solutions from the HumanEval and MBPP datasets. For the EvalPerf dataset, \nno explicit canonical solution is provided. Instead, each problem in EvalPerf is associated \nwith multiple reference implementations, each annotated with an efficiency score. Since a \n1 3\n   62 \n \nPage 12 of 52\nEmpirical Software Engineering           (2026) 31:62 \nhigher efficiency score indicates better performance (Liu et al. 2024a), we select the refer­\nence implementation with the highest efficiency score as the canonical solution for that \nproblem. This enables us to conduct performance regression analysis in a manner consistent \nwith the HumanEval and MBPP datasets. Using the dynamic performance regression detec­\ntion modules, we conduct dynamic performance regression analysis on the generated and \ncanonical code sets of these three datasets. The Python scripts generated for the HumanEval \nand MBPP datasets are typically short and have brief single-run execution times. To gener­\nate more robust performance data, we adopt a technique called repetitive iteration mea­\nsurement (Laaber and Leitner 2018; Ding et al. 2020; Jangali et al. 2023). This technique \nextends the runtime of the generated code by increasing the number of iterations within \nthe test cases, allowing profiling tools to capture more comprehensive performance data. \nWe achieve this extension by adding a for loop at the beginning of the test cases. This loop \ncauses the existing test cases to be executed repeatedly. Figure 5 illustrates this modifica­\ntion for the script shown in Fig. 4. Once the iterations have been increased, we encapsulate \neach"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2.5-testing_streamlit"
}