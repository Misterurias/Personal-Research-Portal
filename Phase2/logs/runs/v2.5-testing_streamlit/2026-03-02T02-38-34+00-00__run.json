{
  "timestamp": "2026-03-02T02:38:34+00:00",
  "query": "Does Github Co-pilot increase developer productivity?",
  "retrieval_query": "How does GitHub Co-pilot affect developer productivity?",
  "query_rewritten": true,
  "rewritten_query": "How does GitHub Co-pilot affect developer productivity?",
  "top_k": 7,
  "answer": "I'll only answer based on the provided evidence chunks. Please provide the specific question or topic you'd like me to address, and I'll do my best to respond using ONLY the information from the evidence chunks.",
  "citations": [],
  "citations_valid": true,
  "invalid_citations": [],
  "references_consistent": false,
  "retrieved": [
    {
      "rank": 1,
      "distance_l2": 0.7041281461715698,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_006",
      "text": " than the control group (Peng et al. 2023). Another\nstudy by GitHub reports that the use of Copilot Chat increases programmers’ confidence, with participants\nself-reporting improvements in code readability, reusability, conciseness, maintainability, and resilience\n(Rodriguez 2023). These productivity gains also translate into labor-market outcomes: developers exposed\nto AI-assisted coding experience faster career progression in the short- to medium-term (Li et al. 2025).\nWork also finds that AI coding assistants reshape the allocation of work. For instance, Yeverechyahu et al.\n5\n(2024) investigate the impact of GitHub Copilot on innovation in OSS projects. They find a significant\nincrease in overall code contributions, accompanied by a shift in the nature of innovation toward more\nroutine and incremental changes. Song et al. (2024) find that Copilot adoption increases project-level code\ncontributions, though this comes at the cost of an increase in coordination time for code integration. Relat-\nedly, Hoffmann et al. (2025) show that access to GitHub Copilot reallocates developers’ effort toward core\ncoding tasks and away from project management and coordination activities.\nWhile AI-assisted code development promises substantial productivity gains, its implications for software\nmaintenance remain less well understood. Prior research on software development has long recognized that\ndevelopment costs are often small relative to maintenance costs, which include sustaining activities associ-\nated with ensuring software quality and security (Nagle 2019). In the case of OSS, while users can benefit\nfrom reduced up-front costs, collective intelligence of the crowd, and flexibility to implement changes, the\nchallenges of maintenance get magnified as contributors are not contractually obligated to maintain the\nsoftware (von Hippel and von Krogh 2003, Nagle 2019). The Linux Foundation’s OSS Contributor Sur-\nvey provides insightful perspectives on the complexities involved in maintaining OSS (Nagle et al. 2020).\nFirstly, it highlights that “general housekeeping\" tasks, such as project maintenance, bug reporting and\ndocumentation, and organizational or administrative duties, often consume a more significant portion of\ncontributors’ time than desired. Secondly, despite a preference among contributors to spend less time on\nmaintenance tasks, there’s a broad acknowledgment of the importance of these activities, especially those\nrelated to software security, for the success and integrity of their projects (Nagle et al. 2020).\nFurthermore, AI code assistants, including prompt-based and “vibe coding” practices, promise to increase\nproductivity while easing access for contributors to submit code, even in complex and mature OSS projects.\nRecent work has begun to examine vibe coding as an emerging and controversial paradigm in AI-assisted\nsoftware development, in which programmers rely on natural language interaction with generative models\nto maintain flow and rapidly explore solutions, often with minimal upfront specification (Pimenova et al.\n2025, Fawzy et al. 2025). While this approach can substantially accelerate development and foster exper-\nimentation, the literature consistently highlights associated risks, including underspecified requirements,\nreduced reliability, difficulties in debugging, increased latency, and heavier burdens on code review and col-\nlaboration (He et al. 2025). A recurring theme is a speed–quality paradox (Fawzy et al. 2025): although vibe\ncoding enables rapid"
    },
    {
      "rank": 2,
      "distance_l2": 0.7502459287643433,
      "source_id": "OpenSourceImpact2024",
      "chunk_id": "OpenSourceImpact2024_chunk_004",
      "text": ", because AI pair programmers not only boost individual code contributions but also encourage \ngreater developer participation. However, because AI pair programmers also encourage more participation \nin discussions on OSS projects, they could lead to longer coordination time for code integration. Moreover, \nwe argue that because of peripheral developers’ lower project familiarity and the limited ability of AI pair \nprogrammers to learn the project’s full context, the increase in project-level code contributions from \nperipheral developers may be smaller than that from core developers. At the same time, code contributed \nby peripheral developers may require more coordination time to integrate than code from core developers. \nOverall, the productivity gains from AI pair programmers may be smaller for peripheral developers than \nfor core developers. \nTo empirically test these hypotheses, we examine how the AI pair programmer, GitHub Copilot, \ninfluences project-level code contributions and coordination time of OSS projects on GitHub, as well as \nhow its effect varies among core versus peripheral developers. GitHub is one of the largest code-hosting \nrepositories based on the Git version control system (Dabbish et al. 2012). In this setting, a repository is a \nfundamental unit that typically contains the source code and resource files for a software project, along with \ninformation related to the project’s evolution history, high-level features, and developer details (Zhang et \nal. 2017). Such repositories are often used to investigate collaborative development practices (Dabbish et \nal. 2012). Our unit of analysis is at the repository-month-level, with the sample period from January 2021 \nto December 2022. To examine our research questions, we use a combination of publicly available data on \nGitHub repositories and proprietary data on Copilot use provided by GitHub organization. Our treatment \n 4 \ngroup consists of repositories where Copilot was both supported by local coding environments and used by \ndevelopers to code. Thus, the post-treatment period includes the months during which Copilot was \nsupported and used in a focal repository, and the pre-treatment period includes all other months. The control \ngroup includes repositories where Copilot was not used throughout the sample period. We estimate our \nmodel using the Generalized Synthetic Control Method (GSCM) and validate the results through alternative \nmatching techniques and a comprehensive set of robustness checks. \nOur empirical results show that the adoption of GitHub Copilot is associated with a 5.9% increase \nin the number of project-level code contributions but also an 8% increase in coordination time for code \nintegration. These findings indicate a tradeoff between contribution gains and coordination time in the OSS \ndevelopment following the adoption of Copilot. Further analysis of the underlying mechanism suggests that \nthe observed increase in project-level code contributions is accompanied by a significant increase in both \nindividual code contributions and developer participation. At the same time, the increase in coordination \ntime is driven by a higher volume of discussions surrounding code contributions, a broader set of developers \nparticipating in these discussions, and greater discussion intensity per developer. Importantly, the combined \neffect of these two competing forces still yields an overall positive effect on the project-level productivity, \nmeasured by the total code contributions with timely integration into the codebase. \nFurthermore, we find that compared to core developers, AI pair programmers lead to a smaller \nincrease in project-level code contributions made by peripheral developers; following the adoption of AI \npair programmers"
    },
    {
      "rank": 3,
      "distance_l2": 0.7573093771934509,
      "source_id": "NoviceProgramming2024",
      "chunk_id": "NoviceProgramming2024_chunk_024",
      "text": " E.;\net al. On the opportunities and risks of foundation models. arXiv 2021, arXiv:2108.07258.\n7.\nZawacki-Richter, O.; Marín, V.I.; Bond, M.; Gouverneur, F. Systematic review of research on artificial intelligence applications in\nhigher education–where are the educators? Int. J. Educ. Technol. High. Educ. 2019, 16, 1–27. [CrossRef]\n8.\nKalliamvakou, E. Research: Quantifying GitHub Copilot’s Impact on Developer Productivity and Happiness. GitHub Blog\n2022. Available online: https://github.blog/news-insights/research/research-quantifying-github-copilots-impact-on-developer-\nproductivity-and-happiness/ (accessed on 1 May 2024).\n9.\nPeng, S.; Kalliamvakou, E.; Cihon, P.; Demirer, M. The impact of ai on developer productivity: Evidence from github copilot.\narXiv 2023, arXiv:2302.06590.\n10.\nFinnie-Ansley, J.; Denny, P.; Becker, B.A.; Luxton-Reilly, A.; Prather, J. The robots are coming: Exploring the implications of\nOpenAI Codex on introductory programming. In Proceedings of the 24th Australasian Computing Education Conference, Virtual\nEvent, 14–18 February 2022; pp. 10–19.\nEduc. Sci. 2024, 14, 1089\n16 of 17\n11.\nYilmaz, R.; Yilmaz, F.G.K. The effect of generative artificial intelligence (AI)-based tool use on students’ computational thinking\nskills, programming self-efficacy and motivation. Comput. Educ. Artif. Intell. 2023, 4, 100147. [CrossRef]\n12.\nBird, C.; Ford, D.; Zimmermann, T.; Forsgren, N.; Kalliamvakou, E.; Lowdermilk, T.; Gazit, I. Taking Flight with Copilot: Early\ninsights and opportunities of AI-powered pair-programming tools. Queue 2022, 20, 35–57. [CrossRef]\n13.\nLau, S.; Guo, P. From “Ban it till we understand it” to “Resistance is futile”: How university programming instructors plan to\nadapt as more students use AI code generation and explanation tools such as ChatGPT and GitHub Copilot. In Proceedings of the\n2023 ACM Conference on International Computing Education Research-Volume 1; Association for Computing Machinery: New York,\nNY, USA, 2023; pp. 106–121.\n14.\nRay, P.P. ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future\nscope. Internet Things Cyber-Phys. Syst. 2023, 3, 121–154. [CrossRef]\n15.\nYin, J.; Goh, T.T.; Yang, B.; Xiaobin, Y. Conversation technology with micro-learning: The impact of chatbot-based learning on\nstudents’ learning motivation and performance. J. Educ. Comput"
    },
    {
      "rank": 4,
      "distance_l2": 0.7740777730941772,
      "source_id": "CopilotCACM2022",
      "chunk_id": "CopilotCACM2022_chunk_001",
      "text": "CODE-COMPLETION SYSTEMS OFFERING suggestions \nto a developer in their integrated development \nenvironment (IDE) have become the most frequently \nused kind of programmer assistance.1 When \ngenerating whole snippets of code, they typically use \na large language model (LLM) to predict what the user \nmight type next (the completion) from the context of \nwhat they are working on at the moment (the prompt).2 \nThis system allows for completions at any position in \nMeasuring \nGitHub \nCopilot’s \nImpact on \nProductivity\nDOI:10.1145/3633453\nCase study asks Copilot users about its impact \non their productivity, and seeks to find their \nperceptions mirrored in user data.\nBY ALBERT ZIEGLER, EIRINI KALLIAMVAKOU, X. ALICE LI, \nANDREW RICE, DEVON RIFKIN, SHAWN SIMISTER, \nGANESH SITTAMPALAM, AND EDWARD AFTANDILIAN\n key insights\n\t\n˽ AI pair-programming tools such as GitHub \nCopilot have a big impact on developer \nproductivity. This holds for developers \nof all skill levels, with junior developers \nseeing the largest gains.\n\t\n˽ The reported benefits of receiving AI \nsuggestions while coding span the full \nrange of typically investigated aspects of \nproductivity, such as task time, product \nquality, cognitive load, enjoyment, and \nlearning.\n\t\n˽ Perceived productivity gains are reflected \nin objective measurements of developer \nactivity.\n\t\n˽ While suggestion correctness is \nimportant, the driving factor for these \nimprovements appears to be not \ncorrectness as such, but whether the \nsuggestions are useful as a starting point \nfor further development.\n54    COMMUNICATIONS OF THE ACM  |  MARCH 2024  |  VOL. 67  |  NO. 3\nresearch\nthe code, often spanning multiple \nlines at once.\nPotential benefits of generating \nlarge sections of code automatically \nare huge, but evaluating these sys­\ntems is challenging. Offline evalua­\ntion, where the system is shown a par­\ntial snippet of code and then asked \nto complete it, is difficult not least \nbecause for longer completions there \nare many acceptable alternatives and \nno straightforward mechanism for \nlabeling them automatically.5 An ad­\nditional step taken by some research­\ners3,21,29 is to use online evaluation \nand track the frequency of real us­\ners accepting suggestions, assuming \nthat the more contributions a system \nmakes to the developer’s code, the \nhigher its benefit. The validity of this \nassumption is not obvious when con­\nsidering issues such as whether two \nshort completions are more valuable \nthan one long one, or whether review­\ning suggestions can be detrimental to \nprogramming flow.\nCode completion in IDEs using lan­\nguage models was first proposed in \nHindle et al.,9 and today neural syn­\nthesis tools such as GitHub Copilot, \nCodeWhisperer, and TabNine suggest \ncode snippets within an IDE with the \nexplicitly stated intention to increase \na user’s productivity. Developer pro­\nductivity has many aspects, and a re­\ncent study has shown that tools like \nthese are helpful in ways"
    },
    {
      "rank": 5,
      "distance_l2": 0.8200198411941528,
      "source_id": "OpenSourceImpact2024",
      "chunk_id": "OpenSourceImpact2024_chunk_032",
      "text": " structure, developers are generally not \nassigned with tasks. Instead, they voluntarily select areas in which they wish to contribute. Given that open-\nsource projects often adopt modular architectures and support parallel development (Howison and \nCrowston 2014, Medappa and Srivastava 2019), core and peripheral developers may contribute \nsimultaneously to similar features, effectively working on the same tasks. As such, task reallocation from \nperipheral to core developers may not be a likely explanation for the observed pattern. \n7. Discussion and Conclusions \nThe rise of AI pair programmers has garnered increasing attention due to their potential to transform \nsoftware development. In this study, we explore the effects of AI pair programmers within the context of \ncollaborative OSS development, with a focus on their impact on project-level code contributions and \ncoordination time for code integration. Using repository-level proprietary data from GitHub organization, \n 34 \nwe evaluate the impact of GitHub Copilot, an AI pair programmer, on the development outcomes of open-\nsource repositories, along with its underlying mechanisms.  \nOur findings indicate that Copilot adoption significantly increases project-level code contribution \nalongside longer coordination time, highlighting a tradeoff between facilitated code generation and \nheightened coordination cost in collaborative software development. Mechanism analyses reveal that the \nincreased project-level code contributions are driven by more developers in participating in coding and \ngreater individual code contributions. In contrast, the increased coordination time seems driven by greater \ncode discussions, including higher code discussion volumes, more developers participating in code \ndiscussions, and greater discussion intensity per developer. We extend prior research on generative AI's \nproductivity benefits for individual developers (e.g., Peng et al. 2023; Cui et al. 2024) by examining its \nimpact on collaborative, voluntary participation in open-source software (OSS) projects. We also contribute \nto the literature on the role of generative AI in team collaboration. Unlike earlier work focused on traditional \nteams with fixed roles and structured coordination (Li et al. 2024, Dell'Acqua et al. 2025), we explore fluid, \nvolunteer-driven OSS environments. We reveal that AI tools, by encouraging engagement in discussions, \nmay increase coordination time due to the need to align diverse perspectives. \nWe also examine the effects of Copilot on core and peripheral developers within the OSS \ncommunity, who differ in their levels of familiarity with the focal projects. Our analysis shows that, \nfollowing Copilot adoption, peripheral developers experienced a relatively smaller increase in project-level \ncode contributions but a larger increase in coordination time, when compared to core developers. In addition, \nwe find that peripheral developers contribute a smaller proportion of timely integrated code, suggesting that \nthe productivity gain from AI pair programmers could be less for peripheral developers than for core \ndevelopers. Prior studies (e.g., Dell’Acqua et al. 2023; Peng et al. 2023) show that less-skilled users often \nbenefit more from AI tools. In contrast, we find that in OSS settings where developers handle complex \nsoftware development projects, core developers gain more from AI pair programming than peripheral ones, \nlikely due to their greater contextual knowledge of the project.  \n7.1 Implications \n 35 \nOur paper has several implications for both practice and the broader OSS communities. First, our findings \nsuggest that organizations should invest in AI pair"
    },
    {
      "rank": 6,
      "distance_l2": 0.8201217651367188,
      "source_id": "OpenSourceImpact2024",
      "chunk_id": "OpenSourceImpact2024_chunk_029",
      "text": ". These normalized metrics allow us to \nassess quality relative to the volume of contributions. As reported in Table 9, we find that although Copilot \nadoption is associated with an increase in the total number of issues and bugs, the normalized measures \nremained statistically unchanged. These findings suggest that the increased issues and bug reports are due \nto a higher volume of code contributions, rather than a reduction in the quality of individual contributions.8 \n[insert Table 9 here] \n6.5 Core and Peripheral Developers \nOur H3a and H3b highlight some differential effects of AI pair programmers between peripheral and core \ndevelopers. To assess the effect of AI pair programmers on the relative project-level code contributions \nmade by peripheral developers compared to core developers (H3a), we compute the proportion of merged \nPRs from peripheral developers to the total number of merged PRs in each repository.9 A negative treatment \neffect estimate on this outcome variable indicates that after using Copilot, the proportion of code generated \nby peripheral developers among all code merged in a repository became lower, i.e. the adoption of AI pair \nprogrammers led to a relative decline in contribution share from peripheral developers.  \n \n8 We also examine whether Copilot’s effects differ by project complexity and find no significant differences between \nsimple and complex projects. Detailed discussions of the results are in Online Appendix J. \n9 Note that there are only two types of developers in a repository: core or peripheral developers. We use this measure \ninstead of the ratio of peripheral developers’ merged PRs to core developers’ merged PRs because the latter measure \ndoes not allow us to incorporate cases where core developers had zero merged PR in a repository in a month.  \n 31 \nTo assess the relative change in coordination time for integrating code contributed by peripheral \ndevelopers compared to the code from core developers (H3b), we calculate the ratio of the average time to \nmerge peripheral developers’ PRs to the overall average code-merging time in each repository. A positive \nestimate on this outcome would indicate that PRs from peripheral developers faced relatively longer \ncoordination time after Copilot adoption.  \nWe next examine the difference in productivity gain from AI pair programmers between peripheral \ndevelopers and core developers. Specifically, we compute the proportion of PRs from peripheral developers \nthat were merged within one, three, or ten days, and use each of these as the dependent variable. Negative \nestimates based on these outcome variables suggest that AI pair programmers led to less productivity gain \nfor peripheral developers than for core developers. \nAs shown in column (1) in Table 10, the proportion of merged PRs from peripheral developers \nsignificantly declined by 0.019 or 3.7%10. Additionally, as shown in column (2), peripheral developers \nexperienced an increase of 0.085 or 5.4%11 in their relative average merge time. Collectively, these findings \nsuggest that Copilot led to relatively fewer project-level code contributions from peripheral developers and \nlonger coordination time for them. The results, as well as the ones in columns (3) to (5) that use the \nproportion of timely merging of peripheral developers’ code as the dependent variables, suggest peripheral \ndevelopers realized less productivity gain from Copilot than core developers. \n[insert Table 10 here] \nTable 11 next reports the results on the mechanisms through which Copilot"
    },
    {
      "rank": 7,
      "distance_l2": 0.8298165798187256,
      "source_id": "AIProdDecrease2024",
      "chunk_id": "AIProdDecrease2024_chunk_002",
      "text": " team member who partners with the developer to create knowledge (Friedman\n2021). Unlike earlier coding automation tools that primarily targeted productivity, GitHub Copilot’s framing\nas a pair programmer signals a deeper shift. It implies that AI may fundamentally reshape how knowledge-\nintensive work is performed, coordinated, and organized, rather than merely accelerating existing tasks.\nFor organizations and communities involved in software development, the addition of AI pair program-\nmers in teams offers the potential for significant productivity gains. Right after the launch of GitHub Copi-\n1\narXiv:2510.10165v3  [econ.GN]  28 Jan 2026\n2\nlot, research shows that developers who use Copilot completed their programming tasks 55.8% faster (Peng\net al. 2023). Such productivity benefits lead to promises of faster time-to-market and increased revenue\nfor organizations developing software applications. Considering these shifts, major tech organizations have\nstarted to increasingly rely on AI in their projects - “more than a quarter of all new code at Google is gen-\nerated by AI, then reviewed and accepted by engineers,\" reported Google CEO Sundar Pichai in January,\n2025.1 Moreover, Microsoft CTO Kevin Scott expects that 95% of all code will be AI-generated by 2030.2\nWhile these productivity gains are promising, they also raise important questions about the quality and\nmaintainability of AI-generated code. Because AI tools can lower the skill barrier for writing code (Dakhel\net al. 2023), AI tools enable broader participation but may also encourage developers to rely on gener-\nated solutions without fully understanding the underlying design rationale and potential integration issues\n(Barrett et al. 2023). Such reliance increases the likelihood of quick fixes that favor short-term function-\nality over long-term maintainability (Barrett et al. 2023). Extant literature characterizes “quick and dirty”\nsoftware customizations made without a complete understanding of their future implications as technical\ndebt, as they undermine system reliability and impose long-term maintenance obligations (Kruchten et al.\n2012, Brown et al. 2010, Banker et al. 2021). As a result, project maintainers must devote additional effort\nto understanding, reviewing, and reworking AI-generated code before it can be safely integrated. In our\ncontext, we contend that the growing reliance on AI-assisted development may accelerate the accumulation\nof technical debt, as design shortcuts taken to expedite system deployment become embedded in software\nsystems (Ramasubbu and Kemerer 2016, 2021).\nThe technical debt and maintenance challenges that AI poses are expected to be especially pronounced\nin distributed software development teams, such as in Open Source Software (OSS) communities. In these\ncommunities, contributors from around the world collaborate, often voluntarily, to develop and maintain\nsoftware that form the digital infrastructure of our society (e.g., Linux, Apache, LaTeX, Python), making\nit freely or cheaply available to the public (Eghbal 2020, Nagle 2019). Despite the voluntary nature of\nwork in these communities, OSS constitutes critical digital infrastructure for modern society, with estimates\nsuggesting that the total cost of reproducing this software would amount to $8.8 trillion (Hoffmann et al.\n2024).3 Given"
    }
  ],
  "embed_model": "sentence-transformers/all-MiniLM-L6-v2",
  "ollama_model": "llama3",
  "prompt_version": "v2-trust-tightened-qrewrite"
}